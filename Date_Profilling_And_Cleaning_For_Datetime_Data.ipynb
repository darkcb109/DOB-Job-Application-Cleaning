{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Downloading\n",
    "\n",
    "Download the data using openClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'DOB Job Application Filings' in file ./ic3t-wcy2.tsv.gz of size 257.98 MB\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import humanfriendly\n",
    "import os\n",
    "\n",
    "from openclean.data.source.socrata import Socrata\n",
    "\n",
    "dataset = Socrata().dataset('ic3t-wcy2')\n",
    "datafile = './ic3t-wcy2.tsv.gz'\n",
    "\n",
    "if not os.path.isfile(datafile):\n",
    "    with gzip.open(datafile, 'wb') as f:\n",
    "        print('Downloading ...\\n')\n",
    "        dataset.write(f)\n",
    "\n",
    "\n",
    "fsize = humanfriendly.format_size(os.stat(datafile).st_size)\n",
    "print(\"Using '{}' in file {} of size {}\".format(dataset.name, datafile, fsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "Load the data into pandas and openClean dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openclean.pipeline import stream\n",
    "\n",
    "df  = pd.read_csv(datafile, dtype='object', sep='\\t')\n",
    "ds = stream(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Profilling for datetime columns\n",
    "\n",
    "Find format problems and outliers in all datetime columns\n",
    "Using openclean's sklearn modules to detect problems and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.profiling.anomalies.sklearn import DBSCANOutliers\n",
    "\n",
    "# Print the ten most frequent values for the 'Vehicle Expiration Date' column.\n",
    "def findDateOutliers(column_name, eps_setting = 0.05):\n",
    "    datetime_data = ds.distinct(column_name)\n",
    "    print(\"Column: \",column_name)\n",
    "    \n",
    "    for rank, val in enumerate(datetime_data.most_common(10)):        \n",
    "        st, freq = val\n",
    "        print('{:<3} {:>8}  {:>10}'.format('{}.'.format(rank + 1), st, '{:,}'.format(freq)))\n",
    "\n",
    "    print('\\nTotal number of distinct values in {} is {}'.format(column_name, len(datetime_data)))\n",
    "    print(DBSCANOutliers().find(datetime_data))\n",
    "    print(DBSCANOutliers(eps = eps_setting).find(datetime_data))\n",
    "    print('\\n==================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime Data columns:\n",
      "\n",
      "Latest Action Date\n",
      "Pre- Filing Date\n",
      "DOBRunDate\n",
      "SIGNOFF_DATE\n",
      "SPECIAL_ACTION_DATE\n",
      "----------------------------\n",
      "\n",
      "Column:  Latest Action Date\n",
      "1.  10/13/2017         793\n",
      "2.  05/18/2017         775\n",
      "3.  01/25/2017         744\n",
      "4.  02/12/2018         739\n",
      "5.  11/30/2016         734\n",
      "6.  07/11/2016         716\n",
      "7.  11/29/2016         700\n",
      "8.  04/30/2018         699\n",
      "9.  05/04/2017         686\n",
      "10. 04/20/2016         674\n",
      "\n",
      "Total number of distinct values in Latest Action Date is 7373\n",
      "['06//1403']\n",
      "['09/15/2003', '01/22/2020', '11/30/2016', '02/22/2000', '02/20/2002', '03/16/2019', '02/22/2002', '11/10/2011', '06/18/2003', '05/18/2017', '02/22/2020', '02/27/2020', '02/12/2018', '05/09/2017', '05/04/2017', '02/05/2020', '06//1403', '02/04/2020', '2020-02-20 ', '04/25/2016', '02/02/2020', '01/25/2017', '06/24/2019', '03/26/2019', '02/02/2000', '08/30/2016', '2018-12-10 ', '07/11/2016', '02/20/2020', '04/16/2019', '02/11/2020', '11/29/2016', '02/02/2002', '2019-05-24 ', '2019-05-17 ', '10/13/2017', '05/19/2017', '04/30/2018', '05/07/2019']\n",
      "\n",
      "==================================\n",
      "Column:  Pre- Filing Date\n",
      "1.  06/28/2019       1,717\n",
      "2.  12/30/2014       1,466\n",
      "3.  06/27/2019       1,388\n",
      "4.  06/26/2008       1,006\n",
      "5.  06/25/2008         842\n",
      "6.  06/26/2019         833\n",
      "7.  09/30/2016         831\n",
      "8.  12/29/2014         808\n",
      "9.  02/04/2011         763\n",
      "10. 02/15/2008         738\n",
      "\n",
      "Total number of distinct values in Pre- Filing Date is 6622\n",
      "[]\n",
      "['12/29/2014', '09/30/2016', '06/27/2019', '06/25/2008', '07/08/2019', '02/22/2020', '09/24/2014', '02/15/2008', '06/30/2009', '07/28/1994', '02/02/2020', '12/23/2014', '06/26/2019', '12/30/2014', '02/04/2011', '06/26/2009', '06/28/2019', '06/26/2008', '11/19/1999']\n",
      "\n",
      "==================================\n",
      "Column:  DOBRunDate\n",
      "1.  04/28/2021 00:00:00   1,676,399\n",
      "2.  07/09/2021 00:00:00      17,146\n",
      "3.  09/16/2021 00:00:00       6,883\n",
      "4.  08/02/2021 00:00:00       2,656\n",
      "5.  11/03/2021 00:00:00       1,709\n",
      "6.  11/09/2021 00:00:00       1,361\n",
      "7.  05/25/2021 00:00:00       1,254\n",
      "8.  07/24/2021 00:00:00       1,206\n",
      "9.  08/31/2021 00:00:00       1,143\n",
      "10. 10/05/2021 00:00:00       1,116\n",
      "\n",
      "Total number of distinct values in DOBRunDate is 297\n",
      "['04/28/2021 00:00:00']\n",
      "['2020-02-21 ', '2020-02-08 ', '2020-02-09 ', '04/28/2021 00:00:00']\n",
      "\n",
      "==================================\n",
      "Column:  SIGNOFF_DATE\n",
      "1.               711,591\n",
      "2.  02/12/2018         603\n",
      "3.  01/25/2017         593\n",
      "4.  05/18/2017         580\n",
      "5.  10/13/2017         576\n",
      "6.  11/30/2016         572\n",
      "7.  07/11/2016         558\n",
      "8.  07/19/2012         540\n",
      "9.  11/29/2016         535\n",
      "10. 04/30/2018         526\n",
      "\n",
      "Total number of distinct values in SIGNOFF_DATE is 5920\n",
      "['']\n",
      "['']\n",
      "\n",
      "==================================\n",
      "Column:  SPECIAL_ACTION_DATE\n",
      "1.             1,602,654\n",
      "2.  10/24/2012       5,513\n",
      "3.  05/12/2017         510\n",
      "4.  10/23/2012         229\n",
      "5.  02/10/2017         224\n",
      "6.  08/13/2019         188\n",
      "7.  03/02/2015         186\n",
      "8.  06/27/2017         181\n",
      "9.  03/02/2017         172\n",
      "10. 11/10/2015         156\n",
      "\n",
      "Total number of distinct values in SPECIAL_ACTION_DATE is 6374\n",
      "['']\n",
      "['', '11//2006']\n",
      "\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "date_cols = []\n",
    "\n",
    "print(\"Datetime Data columns:\\n\")\n",
    "for col in ds.columns:\n",
    "    if 'Date' in col or 'DATE' in col:\n",
    "        print(col)\n",
    "        date_cols.append(col)\n",
    "\n",
    "print(\"----------------------------\\n\")        \n",
    "        \n",
    "for col in date_cols:\n",
    "    findDateOutliers(col, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "the above results show the problems for the data cleaning task:\n",
    "    \n",
    "### Latest Action Date\n",
    "outliers: '06//1403'\n",
    "format: 'yyyy-mm-dd' and 'mm/dd/yyyy'\n",
    "\n",
    "### Pre- Filing Date\n",
    "no problem found\n",
    "\n",
    "### DOBRunDate\n",
    "format: 'yyyy-mm-dd' and 'mm/dd/yyyy 00:00:00'\n",
    "\n",
    "### SIGNOFF_DATE\n",
    "outliers: empty value\n",
    "\n",
    "### SPECIAL_ACTION_DATE\n",
    "outliers: empty value and '11//2006'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for datetime columns\n",
    "\n",
    "* how to deal with empty values has not decided yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "\n",
    "# Reload the data, only for test\n",
    "# new_df = pd.read_csv(datafile, dtype='object', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Latest Action Date'] = new_df['Latest Action Date'].replace('06//1403', '')\n",
    "new_df['Latest Action Date'] = pd.to_datetime(new_df['Latest Action Date']).dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['DOBRunDate'] = pd.to_datetime(new_df['DOBRunDate']).dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['SPECIAL_ACTION_DATE'] = new_df['SPECIAL_ACTION_DATE'].replace('11//2006', '')\n",
    "new_df['SPECIAL_ACTION_DATE'] = pd.to_datetime(new_df['SPECIAL_ACTION_DATE']).dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
