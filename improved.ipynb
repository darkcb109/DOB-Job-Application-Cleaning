{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General version of data cleaning\n",
    "\n",
    "This code will automatically perform data cleaning on each of the dataset in the directoty, to run this notebook you need to download all the datasets and place them in the current directoty with the notebook.\n",
    "\n",
    "Because we automatically find columns and fix them, we can not afford clustering to find outliers for each datasets so remove it in this notebook, the precision and recall rate might be influenced.\n",
    "\n",
    "Run the code in oreder to perform data clean, cleaned data will be save in the current directoty, and to calculate the precision and recall rate, you will need to manually inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openclean\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import humanfriendly\n",
    "import os\n",
    "\n",
    "from openclean.data.source.socrata import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openclean.pipeline import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_list = ['hg8x-zxpr','w9ak-ipjd','dm9a-ab7w','bx6-tga4','ipu4-2q9a','xubg-57si', 'bty7-2jhb', 'hcir-3275, 'pitm-atqc','iz2q-9x8d']\n",
    "# dataset_names = ['Housing New York Units by Building',\n",
    "#                  'DOB NOW: Build – Job Application Filings',\n",
    "#                  'DOB NOW: Electrical Permit Applications', \n",
    "#                  'DOB NOW: Build – Approved Permits',\n",
    "#                  'DOB Permit Issuance', \n",
    "#                  'DOB NOW: Safety – Facades Compliance Filings',\n",
    "#                  'Historical DOB Permit Issuance', \n",
    "#                  'Buildings Selected for the Alternative Enforcement Program (AEP)', \n",
    "#                  'Open Restaurant Applications', \n",
    "#                  'DOB Cellular Antenna Filings']\n",
    "\n",
    "# dataset = Socrata().dataset('pitm-atqc')\n",
    "# datafile = './pitm-atqc.tsv.gz'\n",
    "\n",
    "# if not os.path.isfile(datafile):\n",
    "#     with gzip.open(datafile, 'wb') as f:\n",
    "#         print('Downloading ...\\n')\n",
    "#         dataset.write(f)\n",
    "\n",
    "\n",
    "# fsize = humanfriendly.format_size(os.stat(datafile).st_size)\n",
    "# print(\"Using '{}' in file {} of size {}\".format(dataset.name, datafile, fsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOB Cellular Antenna Filings: iz2q-9x8d\n",
    "# Open Restaurant Applications: pitm-atqc\n",
    "# DOB NOW: Safety – Facades Compliance Filings: xubg-57si\n",
    "# DOB Permit Issuance: ipu4-2q9a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"*.tsv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ipu4-2q9a.tsv.gz',\n",
       " 'iz2q-9x8d.tsv.gz',\n",
       " 'pitm-atqc.tsv.gz',\n",
       " 'xubg-57si.tsv.gz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(file):\n",
    "    \n",
    "    datafile = './'+file\n",
    "    \n",
    "    df  = pd.read_csv(datafile, dtype='object', sep='\\t')\n",
    "    #ds = stream(datafile)\n",
    "    \n",
    "    return datafile, df#, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixColumnNames(df):\n",
    "    rename_list = list(df.columns)\n",
    "    rename_dict = dict()\n",
    "\n",
    "    for i in rename_list:\n",
    "        col_name = str(i)\n",
    "\n",
    "        col_name = col_name.strip().replace(\"_\", \" \").replace(\"’\", \"'\").replace(\".\", \"\")\n",
    "\n",
    "\n",
    "        # https://stackoverflow.com/questions/2277352/split-a-string-at-uppercase-letters\n",
    "        # Split on upper case to seperate cocnatenated words:\n",
    "        if (not col_name.islower()) and (not col_name.isupper()) and (col_name.find(\" \") == -1):\n",
    "            col_name = \" \".join(re.sub(\"([A-Z])\", r\" \\1\", col_name).split())\n",
    "\n",
    "\n",
    "        if col_name.islower(): \n",
    "            col_name = col_name.title()\n",
    "\n",
    "        if (col_name.isupper()) and (col_name.find(\" \") != -1):\n",
    "            col_name = col_name.title()\n",
    "\n",
    "        col_name = col_name.replace(\"No.\", \"Number\")\n",
    "        col_name = col_name.replace(\"#\", \"Number\")\n",
    "\n",
    "        rename_dict[i] = col_name\n",
    "    return rename_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColumns(df, column_name_list):\n",
    "    data_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        for name in column_name_list:\n",
    "            if name.lower() in col.lower():\n",
    "                data_cols.append(col)\n",
    "                \n",
    "    return  data_cols        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_House_Number_Column(df, col):\n",
    "    df[col] = df[col].str.replace(pat='(?P<one>\\\\d)(?P<two>[A-Z]+)', repl='\\g<one> \\g<two>', regex=True)\n",
    "    df[col] = df[col].str.replace(pat='(?P<one>GAR$)', repl='GARAGE', regex=True)\n",
    "    df[col] = df[col].str.replace(pat='NORTH([A-Z]+)?', repl='', regex=True)\n",
    "    df[col] = df[col].str.replace(pat='EAST([A-Z]+)?', repl='', regex=True)\n",
    "    df[col] = df[col].str.replace(pat='SOUTH([A-Z]+)?', repl='', regex=True)\n",
    "    df[col] = df[col].str.replace(pat='WEST([A-Z]+)?', repl='', regex=True)\n",
    "    df.loc[(~df[col].str.contains('\\\\d', regex=True)), col] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Phone_Number_Column(df, col):\n",
    "    \n",
    "    df[col] = df[col].str.replace(pat=\"[^\\\\d]\", repl=\"\", regex=True)    \n",
    "    df[col] = df[col].str.lstrip('1')\n",
    "    df.loc[df[col].str.len()!=10, col] = ''\n",
    "\n",
    "    #return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ID_Number_Column(df):\n",
    "    data_cols = findColumns(df, ['number', 'Number',' No',' NO'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col].fillna('', inplace=True)\n",
    "        df[col] = df[col].astype('str')\n",
    "        df[col] = df[col].str.upper()\n",
    "\n",
    "        df.loc[df[col].str.strip('')=='ONE', col] = '1'\n",
    "        df.loc[df[col].str.strip('')=='TWO', col] = '2'\n",
    "        df.loc[df[col].str.strip('')=='THREE', col] = '3'\n",
    "        df.loc[df[col].str.strip('')=='FOUR', col] = '4'\n",
    "        df.loc[df[col].str.strip('')=='FIVE', col] = '5'\n",
    "        df.loc[df[col].str.strip('')=='SIX', col] = '6'\n",
    "        df.loc[df[col].str.strip('')=='SEVEN', col] = '7'\n",
    "        df.loc[df[col].str.strip('')=='EIGHT', col] = '8'\n",
    "        df.loc[df[col].str.strip('')=='NINE', col] = '9'\n",
    "\n",
    "        df.loc[df[col].str.strip('')=='NONE', col] = ''\n",
    "        df.loc[df[col].str.strip('')=='none', col] = ''\n",
    "        df.loc[df[col].str.strip('')=='None', col] = ''\n",
    "\n",
    "        df.loc[df[col].str.strip('')=='NAN', col] = ''\n",
    "        df.loc[df[col].str.strip('')=='nan', col] = ''\n",
    "        df.loc[df[col].str.strip('')=='NaN', col] = ''\n",
    "        \n",
    "        df.loc[df[col].str.strip('')=='NO NUMBER', col] = ''\n",
    "    \n",
    "        if ('house' in col.lower()) or ('building' in col.lower()):\n",
    "            fix_House_Number_Column(df, col)\n",
    "        if (\"phone\" in col.lower()):\n",
    "            fix_Phone_Number_Column(df, col)\n",
    "    \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Binary_Column(df):\n",
    "    #data_cols = findColumns(ds, ['Landmarked','Owned', 'Filled'])\n",
    "    #\n",
    "    data_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # If column has small # of values, and potentially boolean values like Yes/ No, Y/N, X, True, etc.\n",
    "        if (df[col].nunique() < 5) and (df[df[col].str.lower()==('y|yes|x|true|n|no|false')][col].count() != 0):\n",
    "            data_cols.append(col)\n",
    "        \n",
    "        \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df.loc[df[col].str.lower().isin(['y','yes', 'x', 'true']), col] = True\n",
    "        df.loc[df[col].str.lower().isin(['n', 'no', 'nan','false']), col] = False\n",
    "        df.loc[df[col].str.lower()=='', col] = False\n",
    "        df[col].fillna(False, inplace=True)\n",
    "        \n",
    "        if df[col].nunique()==2:\n",
    "            df[col] = df[col].astype('bool')\n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Monetary_Column(df):\n",
    "    data_cols = findColumns(df, ['Cost','cost', 'fee', 'Fee'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col] = df[col].astype('str')\n",
    "        df[col] = df[col].str.replace(\"$\", '', regex=False)\n",
    "        df[col] = df[col].str.replace(\"-\", '', regex=False)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Numerical_Column(df):\n",
    "    data_cols = findColumns(df, ['Units','units', 'Height', 'height', 'Length', 'length', 'Footage', 'footage', 'Sqft', 'sqft'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        df[col] = df[col].astype('str')\n",
    "\n",
    "        df[col] = df[col].str.replace('-', '', regex=False)\n",
    "        df[col] = df[col].str.replace('NONE', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('none', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('NAN', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('NaN', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('nan', '0', regex=False)\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.profiling.anomalies.sklearn import DBSCANOutliers\n",
    "\n",
    "def findDateOutliers(df, column_name, eps_setting = 0.05):\n",
    "    datetime_data = df[column_name]\n",
    "\n",
    "    light_outliers = DBSCANOutliers().find(datetime_data)\n",
    "    \n",
    "    return light_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datetime_Column(df):\n",
    "    data_cols = findColumns(df, ['date', 'Date', 'DATE'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "    \n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "        light_outliers = findDateOutliers(df, col)\n",
    "        \n",
    "        for item in light_outliers:\n",
    "            \n",
    "            df[col] = df[col].replace(item, None)\n",
    "         \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.data.refdata import RefStore\n",
    "\n",
    "refdata = RefStore()\n",
    "city_df = refdata\\\n",
    "    .load('encyclopaedia_britannica:us_cities', auto_download=True)\\\n",
    "    .df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster string using kNN clusterer (with the default n-gram setting)\n",
    "# using the Levenshtein distance as the similarity measure.\n",
    "\n",
    "from openclean.cluster.knn import knn_clusters\n",
    "from openclean.function.similarity.base import SimilarityConstraint\n",
    "from openclean.function.similarity.text import LevenshteinDistance\n",
    "from openclean.function.value.threshold import GreaterThan\n",
    "\n",
    "def getClusters(df, col, minsize = 2, preds = 0.5): #ds\n",
    "    dba = df.select(col).distinct()\n",
    "    clusters = knn_clusters(\n",
    "        values=dba,\n",
    "        sim=SimilarityConstraint(func=LevenshteinDistance(), pred=GreaterThan(preds)),\n",
    "        minsize=minsize\n",
    "    )\n",
    "    return clusters\n",
    "\n",
    "def print_cluster(cnumber, cluster):\n",
    "    item_count = 0\n",
    "\n",
    "def updateUsingClusters(df, col, clusters, isPrint = False): # ds,\n",
    "    \n",
    "    orignal_list = []\n",
    "    suggestion_list = []\n",
    "    clusters.sort(key=lambda c: len(c), reverse=True)\n",
    "       \n",
    "    for i, cluster in enumerate(clusters):        \n",
    "        suggestion = cluster.suggestion()\n",
    "        orignal_list = []\n",
    "        suggestion_list = []\n",
    "        if isPrint and i <5:\n",
    "            print_cluster(i, cluster)\n",
    "        \n",
    "        for val, count in cluster.items(): \n",
    "            orignal_list.append(val)\n",
    "            suggestion_list.append(suggestion)\n",
    "    \n",
    "    df[col] = df[col].replace(orignal_list, suggestion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.eval.base import Col, Eval\n",
    "from openclean.function.eval.logic import And\n",
    "from openclean.function.value.phonetic import Soundex, soundex\n",
    "\n",
    "\n",
    "def fix_city_and_name_Column(df, file): #ds,\n",
    "    data_cols = findColumns(df, ['NAME', 'name', 'Name','city', 'City', 'CITY', 'BOROUGH', 'Borough', 'borough'])\n",
    "    name_cols = findColumns(df, ['NAME', 'name', 'Name'])\n",
    "    \n",
    "    # mapping list to replace outliers\n",
    "    outlier1 = ['', 'MR. ROSS ADAM C', 'MICHAEL', 'N. J.', 'WILLIAM 11', 'JOSEP;H``', 'DAID/11/2007', 'CHUNG   LUN', '718 9215010', 'ANTHONY', 'HSIA0-NAN', 'JOSEPH', '``````````', 'ROBERT  `', 'RAJENDRA9956700', '2', 'G.B.M.', 'EUGENE......JR', '6312100', 'CLAUDE,JR.', 'THOMAS``', 'ALAN  L', 'Nab53', 'MR. Y. B', 'J.J', 'PH8ILIP', 'I. M', 'RICHARD', 'ALBERTA S 111 D', 'P ;', 'GENECG.C. ENG &', 'J.J.', '2126202794', 'SHAW  HWA', 'HARRY         H', 'MR DOU8GLAS', '`1D', 'PAUL', 'K. T.', 'JOHN', '...NORMAN', 'EVAN   D', '7184361278BERNA', 'S.D. DON', 'KY00 SUK', 'JJ', 'YURI.`', 'MAD/Y/ARNI', 'ES ON SCH B', 'EUGENE.......JR', 'NEAL', 'F._ERIC', 'RYAN,  JR', 'AASDFASDFASDF', 'LA0-TECH', 'RODNEY   __', 'DAVID', 'G. L.', 'JAMES', 'LESLI8E', '7186054055', 'GEORGE', 'G.B.M', 'DAVID    JON', 'CHUNG---YAO', 'PETER', 'YUBUN(JACK)', 'GLEN A. L.', '1P', 'JUDE.....N.O', 'LEONARD--', 'WILLIAM', 'ANTHONY,111', 'WU(WOODY)', 'GAD/HON-AN', 'GLEN  A.L.', 'J.B. Jr.', 'LORENZO..A', 'J J', '..RAMSEY', 'HUI LI I', 'ANTONIO9', 'ROBERT', '0.BERT', 'DUMMY 2', '...JOSEPH', 'RUSSELL 111', 'THOMAS', 'H./E./CAMELLE', 'LALAL', 'M.E. P.E', 'R0OBIN VINCENT', '--young', 'AKM', 'LE1', 'IK.T.', 'LEO, JR.', 'J. Butch A. Jr.', 'WU (WOODY0', 'PAUL   N', 'CHRISTOPHER']\n",
    "    mapping1 = [None, 'ROSS ADAM C', 'MICHAEL', 'N. J.', 'WILLIAM', 'JOSEPH', None, 'CHUNG LUN', None, 'ANTHONY', 'HSIA0 NAN', 'JOSEPH', None, 'ROBERT', 'RAJENDRA', None, 'G.B.M.', 'EUGENEJR', None, 'CLAUDE JR.', 'THOMAS', 'ALAN  L', 'Nab', 'MR. Y. B', 'J.J', 'PHILIP', 'I. M', 'RICHARD', 'ALBERTA', None, 'GENECG.C. ENG', 'J.J.', None, 'SHAW HWA', 'HARRYH', 'MR DOUGLAS', None, 'PAUL', 'K. T.', 'JOHN', 'NORMAN', 'EVAND', 'BERNA', 'S.D. DON', 'KY00 SUK', 'JJ', 'YURI.`', 'MADYARNI', 'ES ON SCH B', 'EUGENEJR', 'NEAL', 'FERIC', 'RYAN,  JR', 'AASDFASDFASDF', 'LA0 TECH', 'RODNEY', 'DAVID', 'G. L.', 'JAMES', 'LESLIE', None, 'GEORGE', 'G.B.M', 'DAVID JON', 'CHUNG YAO', 'PETER', 'YUBUN(JACK)', 'GLEN A. L.', None, 'JUDE N.O', 'LEONARD--', 'WILLIAM', 'ANTHONY,111', 'WU(WOODY)', 'GAD HON-AN', 'GLEN A.L.', 'J.B. Jr.', 'LORENZOA', 'J J', 'RAMSEY', 'HUI LI I', 'ANTONIO9', 'ROBERT', '0.BERT', 'DUMMY', 'JOSEPH', 'RUSSELL', 'THOMAS', 'H.E.CAMELLE', 'LALAL', 'M.E. P.E', 'R0OBIN VINCENT', 'young', 'AKM', 'LE1', 'IK.T.', 'LEO, JR.', 'J. Butch A. Jr.', 'WU (WOODY0', 'PAUL   N', 'CHRISTOPHER']\n",
    "\n",
    "    outlier2 = ['SHARMA #0', \"0'CONNOR\", 'RUSHTON    UEL', 'UDDIN   Z', 'HINKLEY 1', 'O&#039;CONNOR, P.E.', '.OOK', 'SAMUELS111', 'O&#039;CONNOR', 'CALIENDO', 'SMITH   JR.', 'LO  BUE', '7AN', '+-+ETTIERI', 'SMITH, 111', 'KAMEN   1', '.EE', 'MASS, 1', '.EI', 'Zagaroli 3rd', 'RINI   II', 'KAMEN   R', 'RYAN 11', 'SPI8EZIA L S', 'MUFTIC..A.I.A', 'COSTELLO9 RA A I A', 'CALVANICO', 'LLC.', 'POEPPEL, P.E.', 'HAMA07', 'HINLEY,1', '1212', \"O  ' CONNELL\", 'HURT,JR.,', 'WESOLOWSKI', 'CHEN', '`ING, R.A', 'MARTARELLA 111', 'Gandhi, Ph.D., P.E.', '90I', 'ENNIS 2', 'COSTELLO R A A I A', '3UI', 'N/A', 'HURT,  JR', 'LEHR,1', 'KOHLER, 111', 'GERAZOUNIS', 'Alexander,1', 'LUBOW, R.A. LEED AP', 'RINI,111', '08CZAK', '````````````````````', 'CHAO  R.A.', 'Geier 11', '08NGEL', '08SOLOWSKI', 'I11', 'HINKLEY, 1', 'RUDIKOFF, P.E.', \"O'CONNOR\", 'SHAH   EZ', 'MIELE, JR., P.E.', 'RITTENHOUSE 111', 'AMADI   ISIOFIA', 'HINKLEY,1', 'RENFORE````````', \"O'HARA,JR.\", '73020012', 'PHAGOO   I', 'BRAY.....,', 'LLL', 'BHATHIA,1', 'GANDHI, PH. D., P.E', 'KO K', 'VASSALOTTI 11', 'HURT, JR .', '0018LKLE', 'RINI -111', 'PARIHAR', 'EE', 'L00802', 'ELISE.111', 'KING , R.A', 'CHRYSLER  P E', 'LEHR 1', 'Walters   Jr.', 'LEE', 'RINI  III', 'D&#039;ANGELO', '0UDOLPH III', 'VIEHE-NAESS 111', ',MO', '08E', '47DIKOFF', 'Yu,', '420865380', 'COPELAND', 'ZWIEFEL 3RD', 'PETERSEN', 'King, R.A.,', 'RINI, III', '7APA', 'CHEN   S', 'Hurt  Jr.', 'KATZ', 'NIZAMBAD.(P.E.)', '901BEN', '4153LOO', 'SYED-NAQVI', 'RYAN , JR.', 'K O K O R I S', 'ELISEO111', 'O&#039;CONNELL', 'ZEID61', '---Lewis', '00CHELI', 'MOHAMMAD       +++++', 'METZLER  P E', 'BAILEY', 'GANDHI, PH. D., P.E.', 'TIEMANN.111', 'SMITH.111', 'DI GER0NIMO', 'GANDHI, PH,D., P.E', 'III', 'J C', 'MAGAMI-QAIM-MAGAMI', '+M', 'LO G1UDICE', 'HOQUE', 'RUDIKOFF', 'Y10007OR', 'SMITH,111', 'KING R A FAIA', 'RYAN III, AIA', '08AN', 'STARK 1', 'MASS', 'VICTORI0, R.A', 'RIZVI   A', '21029677', \"3'CONNOR\", 'Wong /  Lai', 'KAPLAN 3', 'GRAICHEN.JR./DAWN/DI', 'GROSSMAN ,PE,F.A.C.I']\n",
    "    mapping2 = ['SHARMA ', \"CONNOR\", 'RUSHTON UEL', 'UDDIN Z', 'HINKLEY ', 'CONNOR P.E.', None, 'SAMUELS', 'CONNOR', 'CALIENDO', 'SMITH JR.', 'LO BUE', None, 'ETTIERI', 'SMITH', 'KAMEN', '.EE', 'MASS', '.EI', 'Zagaroli', 'RINI', 'KAMEN R', 'RYAN', 'SPIEZIA L S', 'MUFTIC.A.I.A', 'COSTELLO9 RA A I A', 'CALVANICO', 'LLC.', 'POEPPEL P.E.', 'HAMA', 'HINLEY', None, \"CONNELL\", 'HURT JR.', 'WESOLOWSKI', 'CHEN', 'ING R.A', 'MARTARELLA', 'Gandhi', None, 'ENNIS ', 'COSTELLO R A A I A', None, None, 'HUR  JR', 'LEHR', 'KOHLER 111', 'GERAZOUNIS', 'Alexander', 'LUBOW R.A. LEED AP', 'RINI',None, None, 'CHAO R.A.', 'Geier', None, 'SOLOWSKI', None, 'HINKLEY', 'RUDIKOFF, P.E.', \"CONNOR\", 'SHAH EZ', 'MIELE JR. P.E.', 'RITTENHOUSE', 'AMADI   ISIOFIA', 'HINKLEY', 'RENFORE', \"O'HARA,JR.\", None, 'PHAGOO I', 'BRAY,', 'LLL', 'BHATHIA', 'GANDHI', 'KO K', 'VASSALOTTI', 'HURT JR.',None, 'RINI', 'PARIHAR', 'EE', None, 'ELISE', 'KING R.A', 'CHRYSLER  P E', 'LEHR', 'Walters Jr.', 'LEE', 'RINI  III', 'ANGELO', '0UDOLPH III', 'VIEHE-NAESS', 'MO', '08E', None, 'Yu,', None, 'COPELAND', 'ZWIEFEL 3RD', 'PETERSEN', 'King, R.A.,', 'RINI, III', '7APA', 'CHEN   S', 'Hurt  Jr.', 'KATZ', 'NIZAMBAD.(P.E.)', None, None, None, 'RYAN JR.', 'KOKORIS', 'ELISE', 'CONNELL', None, 'Lewis', 'CHELI', 'MOHAMMAD', 'METZLER  P E', 'BAILEY', 'GANDHI', 'TIEMANN', 'SMITH', 'DI GER0NIMO', 'GANDHI', 'III', 'J C', 'MAGAMI QAIM MAGAMI', None, 'LO G1UDICE', 'HOQUE', 'RUDIKOFF', None, 'SMITH', 'KING R A FAIA', 'RYAN III AIA', None, 'STARK', 'MASS', 'VICTORI0 R.A', 'RIZVIA', None, \"CONNOR\", 'Wong Lai', 'KAPLAN', 'GRAICHEN.JR. DAWN DI', 'GROSSMAN']\n",
    "\n",
    "    outlier3 = ['', '....DEMO', '050069', 'DEM. CONTR.,', 'XXXXX', 'G/C 10114H9', 'CGWC10114H99', '00', 'X S000155', '082-36-1245', 'G.G', 'LESSEE', '......GC', \"'\", '..OWNER', 'GC 2293', '--', 'XXXXXX', 'LS 31,721', '...GC', 'gen.cont.', 'G.C TK#4592', 'PE', 'RLA - 818', '.....OWNER', 'RLA 16077', 'G C', 'X 4129892', 'G. C.', 'R.L.A', 'GC 1028350', 'WC10114H99', 'LEESEE', 'GEN.CONT.', 'SIGN..HANGER', 'DEMO 20451', 'D8615', '.X', 'P.L.L.C', '..DEMO', 'G .C', 'L A', 'G.C NY11101', '32820', '....OWNER', 'GC(DEMO)', 'C0NTRACTOR', 'EXPEDITORC99792', 'X 1341946', 'TRACK# 1390', 'EXPED.R4466', 'PLLC 9599691', 'G.C 1110101', '029649', '(CHECK)', 'DEM. CONTR,', 'EXPEDIT(H66172)', '.........GC', 'CITY OF N Y', 'GC 1170386', 'G. C', 'CO0OWNER', '(CHECKED)', 'C.C', '23392 1159774', 'DEMO {', 'RA', 'T. 31132', '....GC', 'RLA-787', 'TRACK #1390', 'D C', 'G.CONTR.', 'DEMO  CONT', '1GC', 'CC', 'demo G.C.', 'TRACK. #1390', 'M.F.S.P.C.', '...DEMO', 'DEMO G C', '13328', 'GEN  CONT', 'GC 1221073', \"GC;'\", 'DEMO 1341946', '11234', 'G.C.,', '.....GC', 'LIC.133668259 1', '?', '0WNER', 'C10892', 'GEN..CONT']\n",
    "    mapping3 = [None, 'DEMO', None, 'DEM. CONTR', None, 'G/C', 'CGWC', None, 'X S', None, 'G.G', 'LESSEE', 'GC', None, 'OWNER', 'GC', None, None, 'LS ', 'GC', 'gen.cont.', 'G.C TK', 'PE', 'RLA ', 'OWNER', 'RLA ', 'G C', 'X', 'G. C.', 'R.L.A', 'GC', 'WC', 'LEESEE', 'GEN.CONT.', 'SIGN.HANGER', 'DEMO', None,None, 'P.L.L.C', 'DEMO', 'G.C', 'L A', 'G.C ', None, 'OWNER', 'GC(DEMO)', 'C0NTRACTOR', 'EXPEDITORC', None, 'TRACK', 'EXPED.R', 'PLLC ', 'G.C', None, None, 'DEM. CONTR,', 'EXPEDIT', 'GC', None, 'GC', 'G.C', 'CO0OWNER', None, 'C.C', None, 'DEMO', 'RA', None, 'GC', 'RLA', None, 'D C', 'G.CONTR.', 'DEMO  CONT', 'GC', 'CC', 'demo G.C.', None, 'M.F.S.P.C.', 'DEMO', 'DEMO G C', None, 'GEN  CONT', 'GC ', \"GC \", 'DEMO ', None, 'G.C.', 'GC', 'LIC', None, '0WNER',None, 'GEN.CONT']\n",
    "\n",
    "    outlier4 = ['', '0000GC', '083278', 'DD5615', '0000PB', '00ASB4', 'B81923', '99998', '000N/A', '65569+', '01827O', 'R9526', 'LP0256', 'N/A', '1964', 'ISLAND', '1609', '000PW1', '00DEMO', '0688.6', '00000', '.20929', 'LP0258', '000TOR', '0D8615', '0SWITA', '818', 'O02200', 'DEMO', '196', '1075', '0000NT', '215', '0', '00000`', \"D'ALTO\", '0455', '22377', 'DD8615', '050579', '226', 'SWITA', 'DD6815', 'X02689']\n",
    "    mapping4 = [None, '0000GC', '083278', 'DD5615', '0000PB', '00ASB4', 'B81923', '099998', '000000', '065569', '01827O', '0R9526', 'LP0256',None, '001964',None, '001609', '000PW1', '00DEMO', '006886', '000000', '020929', 'LP0258', '000TOR', '0D8615', '0SWITA', '000818', 'O02200', None, '000196', '001075', '0000NT', '000215', '000000', '000000', None, '000455', '022377', 'DD8615', '050579', '000226', None, 'DD6815', 'X02689']\n",
    "\n",
    "    outliers = outlier1+ outlier2+ outlier3+ outlier4\n",
    "    mappings = mapping1+ mapping2+ mapping3+ mapping4\n",
    "       \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col] = df[col].replace(outliers, mappings)\n",
    "        \n",
    "        '''\n",
    "        if file != 'rbx6-tga4.tsv.gz':\n",
    "            light_outliers = findDateOutliers(df, ds, col)\n",
    "\n",
    "            for item in light_outliers:\n",
    "\n",
    "                df[col] = df[col].replace(item, None)\n",
    "        \n",
    "        \n",
    "        if file != 'hg8x-zxpr.tsv.gz' and col in name_cols:\n",
    "            col_clusters = getClusters(df, ds, col)\n",
    "            updateUsingClusters(df, ds, col, col_clusters, True)\n",
    "         '''\n",
    "        df[col] = df[col].astype('str')\n",
    "        df[col] = df[col].str.upper()\n",
    "        df[col] = df[col].replace(['N/A', 'NA','NONE', 'nan', 'NAN', 'NaN'], [\"\", \"\", \"\", \"\", \"\", \"\"])\n",
    "        df[col] = df[col].str.replace(\".\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\",\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\";\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\"!\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\"?\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\"_\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\"/\", \"\", regex=False)\n",
    "        df[col] = df[col].str.replace(\"\\\\\", \"\", regex=False)\n",
    "        \n",
    "    return data_cols    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDf(df, datafile):\n",
    "    outputpath = datafile[2:11]+'_cleaned_data_improved.csv'\n",
    "    df.to_csv(outputpath,sep=',',index=False,header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleanOnDataset(file):\n",
    "    \n",
    "    print('working on file: ', file)\n",
    "    datafile, df = readData(file)\n",
    "    \n",
    "    cleaned_cols = []\n",
    "    \n",
    "    print(\"fixing Column Names.......\")\n",
    "    col_rename_dict = fixColumnNames(df)\n",
    "    #print(\"Column renaming dictionary:\")\n",
    "    #print(col_rename_dict)\n",
    "    \n",
    "    df = df.rename(columns=col_rename_dict)\n",
    "\n",
    "    print('fixing ID Number Columns......')\n",
    "    cleaned_cols += fix_ID_Number_Column(df)\n",
    "    \n",
    "    print('fixing Binary Columns......')\n",
    "    cleaned_cols += fix_Binary_Column(df)\n",
    "    \n",
    "    print('fixing Monetary Columns......')\n",
    "    cleaned_cols += fix_Monetary_Column(df)\n",
    "    \n",
    "    print('fixing Numerical Columns......')\n",
    "    cleaned_cols += fix_Numerical_Column(df)\n",
    "    \n",
    "    print('fixing Datetime Columns......')\n",
    "    cleaned_cols += fix_datetime_Column(df)\n",
    "    \n",
    "    print('fixing City And Name Column......')\n",
    "    cleaned_cols += fix_city_and_name_Column(df, file)\n",
    "    \n",
    "    saveDf(df, datafile)\n",
    "    \n",
    "    return cleaned_cols, datafile, df, col_rename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp):\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(cleaned_columns, datafile, df, sample_size, col_rename_dict):\n",
    "    df2  = pd.read_csv(datafile, dtype='object', sep='\\t')\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2 = df2.rename(columns=col_rename_dict)\n",
    "    \n",
    "\n",
    "    df_sample_data =  df2.sample(sample_size).copy()\n",
    "    df_new_sample_data = df.loc[df_sample_data.index].copy()\n",
    "    print('sample size: ',sample_size)\n",
    "    \n",
    "    print('total size: ',sample_size * len(cleaned_columns))\n",
    "    print('======================\\n\\n')\n",
    "\n",
    "    same = 0\n",
    "\n",
    "    for col in cleaned_columns:\n",
    "        print(\"column: \", col)\n",
    "        print(\"Original,\\t Cleaned\\n\")\n",
    "        for i in range(sample_size):\n",
    "            df_sample_data.iloc[i].index\n",
    "            if df_new_sample_data[col].iloc[i] == df_sample_data[col].iloc[i]:\n",
    "                print(df_sample_data[col].iloc[i], '\\t',df_new_sample_data[col].iloc[i], '\\t')\n",
    "                same += 1\n",
    "            else:\n",
    "                print(df_sample_data[col].iloc[i], '\\t', df_new_sample_data[col].iloc[i], '\\t*')\n",
    "\n",
    "        print('*   ', same, ' same records   *\\n')\n",
    "        same = 0\n",
    "\n",
    "        print('======================\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOB Permit Issuance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:  ipu4-2q9a.tsv.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/3274794538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_rename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataCleanOnDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/77753700.py\u001b[0m in \u001b[0;36mdataCleanOnDataset\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'working on file: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcleaned_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/4040576056.py\u001b[0m in \u001b[0;36mreadData\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdatafile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#ds = stream(datafile)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m     \"\"\"\n\u001b[0;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cleaned_cols, datafile, df, col_rename_dict = dataCleanOnDataset(file_list[0])\n",
    "cleaned_cols = list(set(cleaned_cols))\n",
    "\n",
    "print(cleaned_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_recall(cleaned_cols, datafile, df, 50, col_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 100\n",
    "fp = 7\n",
    "\n",
    "fn = 0\n",
    "tn = 500 - tp - fp - fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(tp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall(tp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOB Cellular Antenna Filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:  iz2q-9x8d.tsv.gz\n",
      "fixing Column Names.......\n",
      "fixing ID Number Columns......\n",
      "fixing Binary Columns......\n",
      "fixing Monetary Columns......\n",
      "fixing Numerical Columns......\n",
      "fixing Datetime Columns......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rlron\\Anaconda2\\envs\\pyspark\\lib\\site-packages\\pandas\\core\\missing.py:94: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= arr == x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing City And Name Column......\n",
      "['Fee Status', 'House Number', \"Owner's Last Name\", \"Owner's Business Name\", \"Owner's  House Number\", 'Borough', \"Applicant's First Name\", 'Total Est Fee', 'Initial Cost', 'Latest Action Date', \"Owner's First Name\", \"Owner's  Phone Number\", 'Applicant License Number', 'Bin Number', 'D O B Run Date', 'First Permit  Date', 'City', 'Street Name', 'Job Number', 'Doc Number', 'Pre- Filing Date', \"Applicant's Last Name\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_cols, datafile, df, col_rename_dict = dataCleanOnDataset(file_list[1])\n",
    "cleaned_cols = list(set(cleaned_cols))\n",
    "\n",
    "print(cleaned_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size:  50\n",
      "total size:  1100\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Fee Status\n",
      "Original,\t Cleaned\n",
      "\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "nan \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "nan \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "STANDARD \t nan \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  House Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "300          \t 300          \t\n",
      "177          \t 177          \t\n",
      "767          \t 767          \t\n",
      "220          \t 220          \t\n",
      "537          \t 537          \t\n",
      "355          \t 355          \t\n",
      "377          \t 377          \t\n",
      "10           \t 10           \t\n",
      "109-05       \t 109-05       \t\n",
      "531          \t 531          \t\n",
      "460          \t 460          \t\n",
      "46-01        \t 46-01        \t\n",
      "36           \t 36           \t\n",
      "82-40        \t 82-40        \t\n",
      "87           \t 87           \t\n",
      "42-05        \t 42-05        \t\n",
      "5906         \t 5906         \t\n",
      "180-05       \t 180-05       \t\n",
      "423          \t 423          \t\n",
      "262          \t 262          \t\n",
      " OR OCCUPANCY.                                                      |01/16/2015 00:00:00 \t  OR OCCUPANCY.                                                      |01/16/2015 00:00:00 \t\n",
      "408          \t 408          \t\n",
      "331          \t 331          \t\n",
      "600          \t 600          \t\n",
      "280          \t 280          \t\n",
      "356          \t 356          \t\n",
      "405          \t 405          \t\n",
      "730          \t 730          \t\n",
      "913          \t 913          \t\n",
      "nan \t  \t*\n",
      "558          \t 558          \t\n",
      "130          \t 130          \t\n",
      "652          \t 652          \t\n",
      "70           \t 70           \t\n",
      "121          \t 121          \t\n",
      "290          \t 290          \t\n",
      "97           \t 97           \t\n",
      "205-01       \t 205-01       \t\n",
      "495          \t 495          \t\n",
      "4515         \t 4515         \t\n",
      "1534         \t 1534         \t\n",
      "38-20        \t 38-20        \t\n",
      "84-04        \t 84-04        \t\n",
      "54-30        \t 54-30        \t\n",
      "160          \t 160          \t\n",
      "23-57        \t 23-57        \t\n",
      "236          \t 236          \t\n",
      "715          \t 715          \t\n",
      "108          \t 108          \t\n",
      "97           \t 97           \t\n",
      "*    49  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Owner's Last Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "BAILEY                         \t BAILEY                         \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "BISHOP                         \t BISHOP                         \t\n",
      "BISHOP                         \t BISHOP                         \t\n",
      "KALLIF                         \t KALLIF                         \t\n",
      "PLATT                          \t PLATT                          \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "MCCARTHY                       \t MCCARTHY                       \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "EISENBAUM                      \t EISENBAUM                      \t\n",
      "HART                           \t HART                           \t\n",
      "CHENG                          \t CHENG                          \t\n",
      "ROSEN                          \t ROSEN                          \t\n",
      "SWEET                          \t SWEET                          \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "POLLOCK                        \t POLLOCK                        \t\n",
      "LACUGNA                        \t LACUGNA                        \t\n",
      "COAKLEY                        \t COAKLEY                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "nan \t  \t*\n",
      "BISHOP                         \t BISHOP                         \t\n",
      "MERRIMAN                       \t MERRIMAN                       \t\n",
      "BAILEY                         \t BAILEY                         \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "WOOLBERT                       \t WOOLBERT                       \t\n",
      "BRENNAN                        \t BRENNAN                        \t\n",
      "JOVEL                          \t JOVEL                          \t\n",
      "nan \t  \t*\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "BISHOP                         \t BISHOP                         \t\n",
      "MAGISTRO                       \t MAGISTRO                       \t\n",
      "BAILEY                         \t BAILEY                         \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "ANZALONE                       \t ANZALONE                       \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "GROOM                          \t GROOM                          \t\n",
      "AHMED                          \t AHMED                          \t\n",
      "GUIND                          \t GUIND                          \t\n",
      "BAILEY                         \t BAILEY                         \t\n",
      "PINKUS                         \t PINKUS                         \t\n",
      "CHIOU                          \t CHIOU                          \t\n",
      "CIAGLIA                        \t CIAGLIA                        \t\n",
      "SURIANO                        \t SURIANO                        \t\n",
      "SIMON                          \t SIMON                          \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Owner's Business Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "VENDOR, AS AGENT FOR TENANT      \t VENDOR AS AGENT FOR TENANT      \t*\n",
      "ST. JOSEPH PATRON CHURCH         \t ST JOSEPH PATRON CHURCH         \t*\n",
      "BOSTON PROPERTIES                \t BOSTON PROPERTIES                \t\n",
      "AMBER CHARTER SCHOOL             \t AMBER CHARTER SCHOOL             \t\n",
      "LOUCO LLC                        \t LOUCO LLC                        \t\n",
      "355 EAST 4TH STREET ASSOCIATES   \t 355 EAST 4TH STREET ASSOCIATES   \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "ABINGTON HOLDING                 \t ABINGTON HOLDING                 \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "DYKER ASSOCIATES C/O DEVEL. RLTY \t DYKER ASSOCIATES CO DEVEL RLTY \t*\n",
      "460 WEST 34TH ASSOCIATES         \t 460 WEST 34TH ASSOCIATES         \t\n",
      "LAUREL HILL LLC                  \t LAUREL HILL LLC                  \t\n",
      "34-36 WEST 38TH STREET LLC       \t 34-36 WEST 38TH STREET LLC       \t\n",
      "AUSTICORP INC.                   \t AUSTICORP INC                   \t*\n",
      "STELLAR MANAGEMENT               \t STELLAR MANAGEMENT               \t\n",
      "WOODSIDE MANOR INC.              \t WOODSIDE MANOR INC              \t*\n",
      "SMARTLINK LLC AGENT FOR NEW CING \t SMARTLINK LLC AGENT FOR NEW CING \t\n",
      "TREASURE ISLAND STORAGE          \t TREASURE ISLAND STORAGE          \t\n",
      "T-MOBILE                         \t T-MOBILE                         \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "nan \t  \t*\n",
      "T-MOBILE                         \t T-MOBILE                         \t\n",
      "SL GREEN REALTY CORP             \t SL GREEN REALTY CORP             \t\n",
      "AT&T MOBILITY                    \t AT&T MOBILITY                    \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "BECHTEL, AS AGENT FOR TENANT     \t BECHTEL AS AGENT FOR TENANT     \t*\n",
      "SHORE 2 SHORE, AGENT FOR TENANT  \t SHORE 2 SHORE AGENT FOR TENANT  \t*\n",
      "LUCIO A JOVEL                    \t LUCIO A JOVEL                    \t\n",
      "nan \t  \t*\n",
      "VOLTAS REAL ESTATE LLC           \t VOLTAS REAL ESTATE LLC           \t\n",
      "T-MOBILE                         \t T-MOBILE                         \t\n",
      "LAUD REALTY CORP                 \t LAUD REALTY CORP                 \t\n",
      "AT&T MOBILITY                    \t AT&T MOBILITY                    \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "YUNG'S REALTY INC.               \t YUNG'S REALTY INC               \t*\n",
      "AMDON EQUITIES III, LLC          \t AMDON EQUITIES III LLC          \t*\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      " S&B REALTY                      \t  S&B REALTY                      \t\n",
      "T-MOBILE NORTHEAST LLC           \t T-MOBILE NORTHEAST LLC           \t\n",
      "NYCHA                            \t NYCHA                            \t\n",
      "AKM K. AHMED                     \t AKM K AHMED                     \t*\n",
      "LIBERT DEPARTMENT STORES II, INC \t LIBERT DEPARTMENT STORES II INC \t*\n",
      "AT&T MOBILITY                    \t AT&T MOBILITY                    \t\n",
      "SABINA BEST REALTY               \t SABINA BEST REALTY               \t\n",
      "LCT ASSOCIATES                   \t LCT ASSOCIATES                   \t\n",
      "T-MOBILE                         \t T-MOBILE                         \t\n",
      "EDISON PROPERTIES, LLC           \t EDISON PROPERTIES LLC           \t*\n",
      "SHS HYLAN LLC                    \t SHS HYLAN LLC                    \t\n",
      "*    36  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Owner's  House Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "ONE          \t  \t*\n",
      "185          \t 185          \t\n",
      "599          \t 599          \t\n",
      "216          \t 216          \t\n",
      "3260         \t 3260         \t\n",
      "1324         \t 1324         \t\n",
      "4            \t 4            \t\n",
      "950          \t 950          \t\n",
      "4            \t 4            \t\n",
      "1224         \t 1224         \t\n",
      "450          \t 450          \t\n",
      "147-25       \t 147-25       \t\n",
      "200          \t 200          \t\n",
      "82-40        \t 82-40        \t\n",
      "156          \t 156          \t\n",
      "1388         \t 1388         \t\n",
      "14           \t 14           \t\n",
      "109-09       \t 109-09       \t\n",
      "4            \t 4            \t\n",
      "4            \t 4            \t\n",
      "nan \t  \t*\n",
      "4            \t 4            \t\n",
      "420          \t 420          \t\n",
      "1            \t 1            \t\n",
      "4            \t 4            \t\n",
      "4            \t 4            \t\n",
      "300          \t 300          \t\n",
      "5550         \t 5550         \t\n",
      "80-15        \t 80-15        \t\n",
      "nan \t  \t*\n",
      "110          \t 110          \t\n",
      "4            \t 4            \t\n",
      "3200         \t 3200         \t\n",
      "1            \t 1            \t\n",
      "4            \t 4            \t\n",
      "4            \t 4            \t\n",
      "PO BOX       \t  \t*\n",
      "863          \t 863          \t\n",
      "4            \t 4            \t\n",
      "160          \t 160          \t\n",
      "4            \t 4            \t\n",
      "90           \t 90           \t\n",
      "84-04        \t 84-04        \t\n",
      "54-30        \t 54-30        \t\n",
      "ONE          \t  \t*\n",
      "23-57        \t 23-57        \t\n",
      "236          \t 236          \t\n",
      "4            \t 4            \t\n",
      "100          \t 100          \t\n",
      "651          \t 651          \t\n",
      "*    45  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Borough\n",
      "Original,\t Cleaned\n",
      "\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "4 \t 4 \t\n",
      "4 \t 4 \t\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      " EGRESS \t  EGRESS \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "3 \t 3 \t\n",
      "nan \t  \t*\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "2 \t  \t*\n",
      "5 \t 5 \t\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "3 \t 3 \t\n",
      "3 \t 3 \t\n",
      "3 \t 3 \t\n",
      "4 \t 4 \t\n",
      "4 \t 4 \t\n",
      "4 \t 4 \t\n",
      "1 \t 1 \t\n",
      "4 \t 4 \t\n",
      "1 \t 1 \t\n",
      "3 \t 3 \t\n",
      "1 \t 1 \t\n",
      "5 \t 5 \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Applicant's First Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "CHAD            \t CHAD            \t\n",
      "JOHN            \t JOHN            \t\n",
      "JOHN            \t JOHN            \t\n",
      "JOHN            \t JOHN            \t\n",
      "JAMES           \t JAMES           \t\n",
      "PETER           \t PETER           \t\n",
      "JOHN            \t JOHN            \t\n",
      "CHRIS           \t CHRIS           \t\n",
      "JOHN            \t JOHN            \t\n",
      "CHAD            \t CHAD            \t\n",
      "JAMES           \t JAMES           \t\n",
      "PETER           \t PETER           \t\n",
      "CHARLES         \t CHARLES         \t\n",
      "ANTONIO         \t ANTONIO         \t\n",
      "GREGORY         \t GREGORY         \t\n",
      "JAMES           \t JAMES           \t\n",
      "FRANK           \t FRANK           \t\n",
      "PETER           \t PETER           \t\n",
      "MICHAEL         \t MICHAEL         \t\n",
      "NICHOLAS        \t NICHOLAS        \t\n",
      "nan \t  \t*\n",
      "PETER           \t PETER           \t\n",
      "JOHN            \t JOHN            \t\n",
      "PHILIP          \t PHILIP          \t\n",
      "JOHN            \t JOHN            \t\n",
      "GREGORY         \t GREGORY         \t\n",
      "NICHOLAS        \t NICHOLAS        \t\n",
      "CHARLES         \t CHARLES         \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "nan \t  \t*\n",
      "JOHN            \t JOHN            \t\n",
      "PETER           \t PETER           \t\n",
      "STEPHEN         \t STEPHEN         \t\n",
      "STEPHEN         \t STEPHEN         \t\n",
      "JOHN            \t JOHN            \t\n",
      "NICHOLAS        \t NICHOLAS        \t\n",
      "JOHN            \t JOHN            \t\n",
      "JAMES           \t JAMES           \t\n",
      "PETER           \t PETER           \t\n",
      "JOHN            \t JOHN            \t\n",
      "NICHOLAS        \t NICHOLAS        \t\n",
      "JOHN            \t JOHN            \t\n",
      "STEPHEN         \t STEPHEN         \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "PHILLIP         \t PHILLIP         \t\n",
      "NEIL            \t NEIL            \t\n",
      "ANTONIO         \t ANTONIO         \t\n",
      "MICHAEL         \t MICHAEL         \t\n",
      "NICHOLAS        \t NICHOLAS        \t\n",
      "CHAD            \t CHAD            \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Total Est Fee\n",
      "Original,\t Cleaned\n",
      "\n",
      "461.6 \t 461.6 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "379.2 \t 379.2 \t*\n",
      "647 \t 647.0 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "296.8 \t 296.8 \t*\n",
      "276.2 \t 276.2 \t*\n",
      "338 \t 338.0 \t*\n",
      "853 \t 853.0 \t*\n",
      "441 \t 441.0 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "471.9 \t 471.9 \t*\n",
      "894.2 \t 894.2 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "235 \t 235.0 \t*\n",
      "nan \t nan \t*\n",
      "441 \t 441.0 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "195 \t 195.0 \t*\n",
      "338 \t 338.0 \t*\n",
      "338 \t 338.0 \t*\n",
      "338 \t 338.0 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "513.1 \t 513.1 \t*\n",
      "nan \t nan \t*\n",
      "286.5 \t 286.5 \t*\n",
      "441 \t 441.0 \t*\n",
      "523.4 \t 523.4 \t*\n",
      "195 \t 195.0 \t*\n",
      "235 \t 235.0 \t*\n",
      "338 \t 338.0 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "1182.6 \t 1182.6 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "338 \t 338.0 \t*\n",
      "976.6 \t 976.6 \t*\n",
      "595.5 \t 595.5 \t*\n",
      "976.6 \t 976.6 \t*\n",
      "195 \t 195.0 \t*\n",
      "348.3 \t 348.3 \t*\n",
      "410.1 \t 410.1 \t*\n",
      "317.4 \t 317.4 \t*\n",
      "389.5 \t 389.5 \t*\n",
      "286.5 \t 286.5 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Initial Cost\n",
      "Original,\t Cleaned\n",
      "\n",
      "27000 \t 27000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "19000 \t 19000.0 \t*\n",
      "45000 \t 45000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "10900 \t 10900.0 \t*\n",
      "8600 \t 8600.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "65000 \t 65000.0 \t*\n",
      "25000 \t 25000.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "27200 \t 27200.0 \t*\n",
      "69000 \t 69000.0 \t*\n",
      "19500 \t 19500.0 \t*\n",
      "9600 \t 9600.0 \t*\n",
      "5000 \t 5000.0 \t*\n",
      "nan \t nan \t*\n",
      "25000 \t 25000.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "2000 \t 2000.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "32000 \t 32000.0 \t*\n",
      "nan \t nan \t*\n",
      "10000 \t 10000.0 \t*\n",
      "25000 \t 25000.0 \t*\n",
      "32600 \t 32600.0 \t*\n",
      "2200 \t 2200.0 \t*\n",
      "5000 \t 5000.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "97000 \t 97000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "15000 \t 15000.0 \t*\n",
      "76800 \t 76800.0 \t*\n",
      "40000 \t 40000.0 \t*\n",
      "77000 \t 77000.0 \t*\n",
      "2000 \t 2000.0 \t*\n",
      "15200 \t 15200.0 \t*\n",
      "21300 \t 21300.0 \t*\n",
      "12100 \t 12100.0 \t*\n",
      "20000 \t 20000.0 \t*\n",
      "10000 \t 10000.0 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Latest Action Date\n",
      "Original,\t Cleaned\n",
      "\n",
      "02/28/2017 00:00:00 \t 2017-02-28 00:00:00 \t*\n",
      "05/21/2015 00:00:00 \t 2015-05-21 00:00:00 \t*\n",
      "06/26/2015 00:00:00 \t 2015-06-26 00:00:00 \t*\n",
      "07/28/2015 00:00:00 \t 2015-07-28 00:00:00 \t*\n",
      "03/25/2014 00:00:00 \t 2014-03-25 00:00:00 \t*\n",
      "10/29/2015 00:00:00 \t 2015-10-29 00:00:00 \t*\n",
      "11/09/2015 00:00:00 \t 2015-11-09 00:00:00 \t*\n",
      "10/01/2013 00:00:00 \t 2013-10-01 00:00:00 \t*\n",
      "10/26/2016 00:00:00 \t 2016-10-26 00:00:00 \t*\n",
      "02/16/2016 00:00:00 \t 2016-02-16 00:00:00 \t*\n",
      "06/18/2015 00:00:00 \t 2015-06-18 00:00:00 \t*\n",
      "08/05/2015 00:00:00 \t 2015-08-05 00:00:00 \t*\n",
      "06/13/2013 00:00:00 \t 2013-06-13 00:00:00 \t*\n",
      "08/19/2014 00:00:00 \t 2014-08-19 00:00:00 \t*\n",
      "08/21/2015 00:00:00 \t 2015-08-21 00:00:00 \t*\n",
      "10/20/2015 00:00:00 \t 2015-10-20 00:00:00 \t*\n",
      "10/15/2014 00:00:00 \t 2014-10-15 00:00:00 \t*\n",
      "03/20/2015 00:00:00 \t 2015-03-20 00:00:00 \t*\n",
      "01/06/2017 00:00:00 \t 2017-01-06 00:00:00 \t*\n",
      "11/14/2015 00:00:00 \t 2015-11-14 00:00:00 \t*\n",
      "nan \t 2016-08-31 00:00:00 \t*\n",
      "10/21/2015 00:00:00 \t 2015-10-21 00:00:00 \t*\n",
      "01/05/2015 00:00:00 \t 2015-01-05 00:00:00 \t*\n",
      "08/18/2015 00:00:00 \t 2015-08-18 00:00:00 \t*\n",
      "08/11/2015 00:00:00 \t 2015-08-11 00:00:00 \t*\n",
      "10/14/2015 00:00:00 \t 2015-10-14 00:00:00 \t*\n",
      "03/13/2017 00:00:00 \t 2017-03-13 00:00:00 \t*\n",
      "04/03/2017 00:00:00 \t 2017-04-03 00:00:00 \t*\n",
      "07/27/2015 00:00:00 \t 2015-07-27 00:00:00 \t*\n",
      "nan \t 2016-09-21 00:00:00 \t*\n",
      "09/20/2016 00:00:00 \t 2016-09-20 00:00:00 \t*\n",
      "09/18/2015 00:00:00 \t 2015-09-18 00:00:00 \t*\n",
      "07/31/2013 00:00:00 \t 2013-07-31 00:00:00 \t*\n",
      "06/22/2015 00:00:00 \t 2015-06-22 00:00:00 \t*\n",
      "12/08/2015 00:00:00 \t 2015-12-08 00:00:00 \t*\n",
      "06/29/2015 00:00:00 \t 2015-06-29 00:00:00 \t*\n",
      "11/16/2015 00:00:00 \t 2015-11-16 00:00:00 \t*\n",
      "06/24/2015 00:00:00 \t 2015-06-24 00:00:00 \t*\n",
      "09/25/2015 00:00:00 \t 2015-09-25 00:00:00 \t*\n",
      "12/02/2015 00:00:00 \t 2015-12-02 00:00:00 \t*\n",
      "11/12/2015 00:00:00 \t 2015-11-12 00:00:00 \t*\n",
      "05/03/2013 00:00:00 \t 2013-05-03 00:00:00 \t*\n",
      "12/15/2017 00:00:00 \t 2017-12-15 00:00:00 \t*\n",
      "02/14/2014 00:00:00 \t 2014-02-14 00:00:00 \t*\n",
      "05/27/2016 00:00:00 \t 2016-05-27 00:00:00 \t*\n",
      "05/20/2016 00:00:00 \t 2016-05-20 00:00:00 \t*\n",
      "08/26/2016 00:00:00 \t 2016-08-26 00:00:00 \t*\n",
      "05/22/2017 00:00:00 \t 2017-05-22 00:00:00 \t*\n",
      "05/11/2017 00:00:00 \t 2017-05-11 00:00:00 \t*\n",
      "06/10/2015 00:00:00 \t 2015-06-10 00:00:00 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Owner's First Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "GREGG           \t GREGG           \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "MARK            \t MARK            \t\n",
      "MARK            \t MARK            \t\n",
      "TED             \t TED             \t\n",
      "GERALD          \t GERALD          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "DAN             \t DAN             \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "WAYNE           \t WAYNE           \t\n",
      "EDWARD          \t EDWARD          \t\n",
      "SHOW LAIN       \t SHOW LAIN       \t\n",
      "DAVID           \t DAVID           \t\n",
      "JOE             \t JOE             \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ZEV             \t ZEV             \t\n",
      "JAMES           \t JAMES           \t\n",
      "JAMES           \t JAMES           \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "nan \t  \t*\n",
      "MARK            \t MARK            \t\n",
      "ROGER           \t ROGER           \t\n",
      "GREGG           \t GREGG           \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "CHRIS           \t CHRIS           \t\n",
      "VICTORIA        \t VICTORIA        \t\n",
      "LUCIO           \t LUCIO           \t\n",
      "nan \t  \t*\n",
      "ROBERT          \t ROBERT          \t\n",
      "MARK            \t MARK            \t\n",
      "STEVE           \t STEVE           \t\n",
      "GREGG           \t GREGG           \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "DONALD          \t DONALD          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "SCOTT           \t SCOTT           \t\n",
      "AKM             \t AKM             \t\n",
      "ALBERT          \t ALBERT          \t\n",
      "GREGG           \t GREGG           \t\n",
      "GARY            \t GARY            \t\n",
      "SCOTT           \t SCOTT           \t\n",
      "ROBERT          \t ROBERT          \t\n",
      "PASQUALE        \t PASQUALE        \t\n",
      "NEIL            \t NEIL            \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Owner's  Phone Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "9144389326 \t 9144389326 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "9738988589 \t 9738988589 \t\n",
      "9738988589 \t 9738988589 \t\n",
      "5168059180 \t 5168059180 \t\n",
      "9174530716 \t 9174530716 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "2127595000 \t 2127595000 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "8605610121 \t 8605610121 \t\n",
      "2125636252 \t 2125636252 \t\n",
      "7184608020 \t 7184608020 \t\n",
      "2128230850 \t 2128230850 \t\n",
      "5165678478 \t 5165678478 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "7183390500 \t 7183390500 \t\n",
      "8888285465 \t 8888285465 \t\n",
      "7185096543 \t 7185096543 \t\n",
      "9733974800 \t 9733974800 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "nan \t  \t*\n",
      "9738971375 \t 9738971375 \t\n",
      "2122161664 \t 2122161664 \t\n",
      "9144389326 \t 9144389326 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "2018359008 \t 2018359008 \t\n",
      "5165572398 \t 5165572398 \t\n",
      "7188460300 \t 7188460300 \t\n",
      "nan \t  \t*\n",
      "9733974814 \t 9733974814 \t\n",
      "9738971375 \t 9738971375 \t\n",
      "7816528499 \t 7816528499 \t\n",
      "9142633800 \t 9142633800 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "5165106800 \t 5165106800 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "7186245195 \t 7186245195 \t\n",
      "9733974814 \t 9733974814 \t\n",
      "2123065160 \t 2123065160 \t\n",
      "9172855387 \t 9172855387 \t\n",
      "7184175858 \t 7184175858 \t\n",
      "9144389326 \t 9144389326 \t\n",
      "9175770824 \t 9175770824 \t\n",
      "2122138130 \t 2122138130 \t\n",
      "2017573053 \t 2017573053 \t\n",
      "9738492613 \t 9738492613 \t\n",
      "7186988000 \t 7186988000 \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Applicant License Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "093111 \t 093111 \t\n",
      "063658 \t 063658 \t\n",
      "063658 \t 063658 \t\n",
      "063658 \t 063658 \t\n",
      "078939 \t 078939 \t\n",
      "079612 \t 079612 \t\n",
      "063658 \t 063658 \t\n",
      "080438 \t 080438 \t\n",
      "063658 \t 063658 \t\n",
      "093111 \t 093111 \t\n",
      "078939 \t 078939 \t\n",
      "079612 \t 079612 \t\n",
      "087427 \t 087427 \t\n",
      "071249 \t 071249 \t\n",
      "079769 \t 079769 \t\n",
      "078939 \t 078939 \t\n",
      "086873 \t 086873 \t\n",
      "064690 \t 064690 \t\n",
      "075700 \t 075700 \t\n",
      "090133 \t 090133 \t\n",
      "nan \t  \t*\n",
      "064690 \t 064690 \t\n",
      "063658 \t 063658 \t\n",
      "077087 \t 077087 \t\n",
      "063658 \t 063658 \t\n",
      "079769 \t 079769 \t\n",
      "090133 \t 090133 \t\n",
      "028321 \t 028321 \t\n",
      "075384 \t 075384 \t\n",
      "nan \t  \t*\n",
      "063658 \t 063658 \t\n",
      "064690 \t 064690 \t\n",
      "086064 \t 086064 \t\n",
      "086064 \t 086064 \t\n",
      "063658 \t 063658 \t\n",
      "090133 \t 090133 \t\n",
      "063658 \t 063658 \t\n",
      "078939 \t 078939 \t\n",
      "079612 \t 079612 \t\n",
      "063658 \t 063658 \t\n",
      "090133 \t 090133 \t\n",
      "063658 \t 063658 \t\n",
      "086064 \t 086064 \t\n",
      "075384 \t 075384 \t\n",
      "077087 \t 077087 \t\n",
      "026944 \t 026944 \t\n",
      "071249 \t 071249 \t\n",
      "075700 \t 075700 \t\n",
      "090133 \t 090133 \t\n",
      "093111 \t 093111 \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Bin Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "1063499 \t 1063499 \t\n",
      "3072916 \t 3072916 \t\n",
      "1036082 \t 1036082 \t\n",
      "1052428 \t 1052428 \t\n",
      "3082701 \t 3082701 \t\n",
      "1004419 \t 1004419 \t\n",
      "1018161 \t 1018161 \t\n",
      "1010142 \t 1010142 \t\n",
      "4249509 \t 4249509 \t\n",
      "3153220 \t 3153220 \t\n",
      "1012843 \t 1012843 \t\n",
      "4056316 \t 4056316 \t\n",
      "1015978 \t 1015978 \t\n",
      "4079715 \t 4079715 \t\n",
      "1061772 \t 1061772 \t\n",
      "4002131 \t 4002131 \t\n",
      "4083715 \t 4083715 \t\n",
      "4220271 \t 4220271 \t\n",
      "1081691 \t 1081691 \t\n",
      "3244449 \t 3244449 \t\n",
      "nan \t  \t*\n",
      "3000371 \t 3000371 \t\n",
      "1035352 \t 1035352 \t\n",
      "1062302 \t 1062302 \t\n",
      "1065199 \t 1065199 \t\n",
      "1079813 \t 1079813 \t\n",
      "1036476 \t 1036476 \t\n",
      "3102073 \t 3102073 \t\n",
      "3094952 \t 3094952 \t\n",
      "nan \t  \t*\n",
      "1007377 \t 1007377 \t\n",
      "3067815 \t 3067815 \t\n",
      "2021837 \t 2021837 \t\n",
      "5046122 \t 5046122 \t\n",
      "1005882 \t 1005882 \t\n",
      "3101025 \t 3101025 \t\n",
      "1005312 \t 1005312 \t\n",
      "4135513 \t 4135513 \t\n",
      "3336261 \t 3336261 \t\n",
      "3136685 \t 3136685 \t\n",
      "3213513 \t 3213513 \t\n",
      "4302129 \t 4302129 \t\n",
      "4187270 \t 4187270 \t\n",
      "4085393 \t 4085393 \t\n",
      "1018080 \t 1018080 \t\n",
      "4535421 \t 4535421 \t\n",
      "1015687 \t 1015687 \t\n",
      "3379016 \t 3379016 \t\n",
      "1081588 \t 1081588 \t\n",
      "5110105 \t 5110105 \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  D O B Run Date\n",
      "Original,\t Cleaned\n",
      "\n",
      "03/01/2017 00:00:00 \t 2017-03-01 00:00:00 \t*\n",
      "05/22/2015 00:00:00 \t 2015-05-22 00:00:00 \t*\n",
      "06/27/2015 00:00:00 \t 2015-06-27 00:00:00 \t*\n",
      "07/29/2015 00:00:00 \t 2015-07-29 00:00:00 \t*\n",
      "03/26/2014 00:00:00 \t 2014-03-26 00:00:00 \t*\n",
      "10/30/2015 00:00:00 \t 2015-10-30 00:00:00 \t*\n",
      "11/10/2015 00:00:00 \t 2015-11-10 00:00:00 \t*\n",
      "10/02/2013 00:00:00 \t 2013-10-02 00:00:00 \t*\n",
      "10/27/2016 00:00:00 \t 2016-10-27 00:00:00 \t*\n",
      "02/17/2016 00:00:00 \t 2016-02-17 00:00:00 \t*\n",
      "06/19/2015 00:00:00 \t 2015-06-19 00:00:00 \t*\n",
      "08/06/2015 00:00:00 \t 2015-08-06 00:00:00 \t*\n",
      "06/14/2013 00:00:00 \t 2013-06-14 00:00:00 \t*\n",
      "08/20/2014 00:00:00 \t 2014-08-20 00:00:00 \t*\n",
      "08/22/2015 00:00:00 \t 2015-08-22 00:00:00 \t*\n",
      "10/21/2015 00:00:00 \t 2015-10-21 00:00:00 \t*\n",
      "10/16/2014 00:00:00 \t 2014-10-16 00:00:00 \t*\n",
      "03/21/2015 00:00:00 \t 2015-03-21 00:00:00 \t*\n",
      "01/07/2017 00:00:00 \t 2017-01-07 00:00:00 \t*\n",
      "11/15/2015 00:00:00 \t 2015-11-15 00:00:00 \t*\n",
      "nan \t 2016-09-01 00:00:00 \t*\n",
      "10/22/2015 00:00:00 \t 2015-10-22 00:00:00 \t*\n",
      "01/06/2015 00:00:00 \t 2015-01-06 00:00:00 \t*\n",
      "08/19/2015 00:00:00 \t 2015-08-19 00:00:00 \t*\n",
      "08/12/2015 00:00:00 \t 2015-08-12 00:00:00 \t*\n",
      "10/15/2015 00:00:00 \t 2015-10-15 00:00:00 \t*\n",
      "03/14/2017 00:00:00 \t 2017-03-14 00:00:00 \t*\n",
      "04/04/2017 00:00:00 \t 2017-04-04 00:00:00 \t*\n",
      "07/28/2015 00:00:00 \t 2015-07-28 00:00:00 \t*\n",
      "nan \t 2016-09-22 00:00:00 \t*\n",
      "09/21/2016 00:00:00 \t 2016-09-21 00:00:00 \t*\n",
      "09/19/2015 00:00:00 \t 2015-09-19 00:00:00 \t*\n",
      "08/01/2013 00:00:00 \t 2013-08-01 00:00:00 \t*\n",
      "06/23/2015 00:00:00 \t 2015-06-23 00:00:00 \t*\n",
      "12/09/2015 00:00:00 \t 2015-12-09 00:00:00 \t*\n",
      "06/30/2015 00:00:00 \t 2015-06-30 00:00:00 \t*\n",
      "11/17/2015 00:00:00 \t 2015-11-17 00:00:00 \t*\n",
      "06/25/2015 00:00:00 \t 2015-06-25 00:00:00 \t*\n",
      "09/26/2015 00:00:00 \t 2015-09-26 00:00:00 \t*\n",
      "12/03/2015 00:00:00 \t 2015-12-03 00:00:00 \t*\n",
      "11/13/2015 00:00:00 \t 2015-11-13 00:00:00 \t*\n",
      "05/04/2013 00:00:00 \t 2013-05-04 00:00:00 \t*\n",
      "12/16/2017 00:00:00 \t 2017-12-16 00:00:00 \t*\n",
      "02/15/2014 00:00:00 \t 2014-02-15 00:00:00 \t*\n",
      "05/28/2016 00:00:00 \t 2016-05-28 00:00:00 \t*\n",
      "05/21/2016 00:00:00 \t 2016-05-21 00:00:00 \t*\n",
      "08/27/2016 00:00:00 \t 2016-08-27 00:00:00 \t*\n",
      "05/23/2017 00:00:00 \t 2017-05-23 00:00:00 \t*\n",
      "05/12/2017 00:00:00 \t 2017-05-12 00:00:00 \t*\n",
      "06/11/2015 00:00:00 \t 2015-06-11 00:00:00 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  First Permit  Date\n",
      "Original,\t Cleaned\n",
      "\n",
      "02/28/2017 12:00:00 AM \t 2017-02-28 00:00:00 \t*\n",
      "05/21/2015 12:00:00 AM \t 2015-05-21 00:00:00 \t*\n",
      "06/26/2015 12:00:00 AM \t 2015-06-26 00:00:00 \t*\n",
      "07/28/2015 12:00:00 AM \t 2015-07-28 00:00:00 \t*\n",
      "03/25/2014 12:00:00 AM \t 2014-03-25 00:00:00 \t*\n",
      "10/29/2015 12:00:00 AM \t 2015-10-29 00:00:00 \t*\n",
      "11/09/2015 12:00:00 AM \t 2015-11-09 00:00:00 \t*\n",
      "10/01/2013 12:00:00 AM \t 2013-10-01 00:00:00 \t*\n",
      "10/26/2016 12:00:00 AM \t 2016-10-26 00:00:00 \t*\n",
      "02/16/2016 12:00:00 AM \t 2016-02-16 00:00:00 \t*\n",
      "06/18/2015 12:00:00 AM \t 2015-06-18 00:00:00 \t*\n",
      "08/05/2015 12:00:00 AM \t 2015-08-05 00:00:00 \t*\n",
      "06/13/2013 12:00:00 AM \t 2013-06-13 00:00:00 \t*\n",
      "08/19/2014 12:00:00 AM \t 2014-08-19 00:00:00 \t*\n",
      "08/21/2015 12:00:00 AM \t 2015-08-21 00:00:00 \t*\n",
      "10/20/2015 12:00:00 AM \t 2015-10-20 00:00:00 \t*\n",
      "10/15/2014 12:00:00 AM \t 2014-10-15 00:00:00 \t*\n",
      "03/20/2015 12:00:00 AM \t 2015-03-20 00:00:00 \t*\n",
      "01/06/2017 12:00:00 AM \t 2017-01-06 00:00:00 \t*\n",
      "11/14/2015 12:00:00 AM \t 2015-11-14 00:00:00 \t*\n",
      "nan \t 2016-08-31 00:00:00 \t*\n",
      "10/21/2015 12:00:00 AM \t 2015-10-21 00:00:00 \t*\n",
      "01/05/2015 12:00:00 AM \t 2015-01-05 00:00:00 \t*\n",
      "08/18/2015 12:00:00 AM \t 2015-08-18 00:00:00 \t*\n",
      "08/11/2015 12:00:00 AM \t 2015-08-11 00:00:00 \t*\n",
      "10/14/2015 12:00:00 AM \t 2015-10-14 00:00:00 \t*\n",
      "03/13/2017 12:00:00 AM \t 2017-03-13 00:00:00 \t*\n",
      "04/03/2017 12:00:00 AM \t 2017-04-03 00:00:00 \t*\n",
      "07/27/2015 12:00:00 AM \t 2015-07-27 00:00:00 \t*\n",
      "nan \t 2016-09-21 00:00:00 \t*\n",
      "09/20/2016 12:00:00 AM \t 2016-09-20 00:00:00 \t*\n",
      "09/18/2015 12:00:00 AM \t 2015-09-18 00:00:00 \t*\n",
      "07/31/2013 12:00:00 AM \t 2013-07-31 00:00:00 \t*\n",
      "06/22/2015 12:00:00 AM \t 2015-06-22 00:00:00 \t*\n",
      "12/08/2015 12:00:00 AM \t 2015-12-08 00:00:00 \t*\n",
      "06/29/2015 12:00:00 AM \t 2015-06-29 00:00:00 \t*\n",
      "11/16/2015 12:00:00 AM \t 2015-11-16 00:00:00 \t*\n",
      "06/24/2015 12:00:00 AM \t 2015-06-24 00:00:00 \t*\n",
      "09/25/2015 12:00:00 AM \t 2015-09-25 00:00:00 \t*\n",
      "12/02/2015 12:00:00 AM \t 2015-12-02 00:00:00 \t*\n",
      "11/12/2015 12:00:00 AM \t 2015-11-12 00:00:00 \t*\n",
      "05/03/2013 12:00:00 AM \t 2013-05-03 00:00:00 \t*\n",
      "12/15/2017 12:00:00 AM \t 2017-12-15 00:00:00 \t*\n",
      "02/14/2014 12:00:00 AM \t 2014-02-14 00:00:00 \t*\n",
      "05/27/2016 12:00:00 AM \t 2016-05-27 00:00:00 \t*\n",
      "05/20/2016 12:00:00 AM \t 2016-05-20 00:00:00 \t*\n",
      "08/26/2016 12:00:00 AM \t 2016-08-26 00:00:00 \t*\n",
      "05/22/2017 12:00:00 AM \t 2017-05-22 00:00:00 \t*\n",
      "05/11/2017 12:00:00 AM \t 2017-05-11 00:00:00 \t*\n",
      "06/10/2015 12:00:00 AM \t 2015-06-10 00:00:00 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  City\n",
      "Original,\t Cleaned\n",
      "\n",
      "BEDMINSTER      \t BEDMINSTER      \t\n",
      "BROOKYLN        \t BROOKYLN        \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "BROOKLYN        \t BROOKLYN        \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "EAST BERLIN     \t EAST BERLIN     \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "FLUSHING        \t FLUSHING        \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "KEW GARDENS     \t KEW GARDENS     \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "BROOKLYN        \t BROOKLYN        \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "QUEENS          \t QUEENS          \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "nan \t  \t*\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "BEDMINSTER      \t BEDMINSTER      \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "BLOOMFIELD      \t BLOOMFIELD      \t\n",
      "MASSAPEQUA      \t MASSAPEQUA      \t\n",
      "WOODHAVEN       \t WOODHAVEN       \t\n",
      "nan \t  \t*\n",
      "ATLANTIC BEACH  \t ATLANTIC BEACH  \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "BRONX           \t BRONX           \t\n",
      "BEDMINSTER      \t BEDMINSTER      \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "OLD BROOKVILLE  \t OLD BROOKVILLE  \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "BROOKLYN        \t BROOKLYN        \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "OZONE PARK      \t OZONE PARK      \t\n",
      "RIDGEWOOD       \t RIDGEWOOD       \t\n",
      "BEDMINSTER      \t BEDMINSTER      \t\n",
      "JACKSON         \t JACKSON         \t\n",
      "NEW YORK        \t NEW YORK        \t\n",
      "PARSIPPANY      \t PARSIPPANY      \t\n",
      "NEWARK          \t NEWARK          \t\n",
      "STATEN ISLAND   \t STATEN ISLAND   \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Street Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "FORT WASHINGTON AVENUE           \t FORT WASHINGTON AVENUE           \t\n",
      "SUYDAM STREET                    \t SUYDAM STREET                    \t\n",
      "5TH AVENUE                       \t 5TH AVENUE                       \t\n",
      "EAST 106TH STREET                \t EAST 106TH STREET                \t\n",
      "HERZL STREET                     \t HERZL STREET                     \t\n",
      "EAST 4TH STREET                  \t EAST 4TH STREET                  \t\n",
      "PARK AVENUE SOUTH                \t PARK AVENUE SOUTH                \t\n",
      "JONES STREET                     \t JONES STREET                     \t\n",
      "120 STREET                       \t 120 STREET                       \t\n",
      "86 STREET                        \t 86 STREET                        \t\n",
      "WEST 34TH STREET                 \t WEST 34TH STREET                 \t\n",
      "67TH STREET                      \t 67TH STREET                      \t\n",
      "WEST 38TH STREET                 \t WEST 38TH STREET                 \t\n",
      "AUSTIN STREET                    \t AUSTIN STREET                    \t\n",
      "HAMILTON PLACE                   \t HAMILTON PLACE                   \t\n",
      "48TH AVENUE                      \t 48TH AVENUE                      \t\n",
      "LINDEN STREET                    \t LINDEN STREET                    \t\n",
      "110 AVE                          \t 110 AVE                          \t\n",
      "EAST 23RD STREET                 \t EAST 23RD STREET                 \t\n",
      "NEPTUNE AVENUE                   \t NEPTUNE AVENUE                   \t\n",
      "nan \t  \t*\n",
      "JAY STREET                       \t JAY STREET                       \t\n",
      "MADISON AVE                      \t MADISON AVE                      \t\n",
      "WEST 139TH STREET                \t WEST 139TH STREET                \t\n",
      "RECTOR PLACE                     \t RECTOR PLACE                     \t\n",
      "WEST 145TH STREET                \t WEST 145TH STREET                \t\n",
      "PARK AVENUE                      \t PARK AVENUE                      \t\n",
      "LINDEN BOULEVARD                 \t LINDEN BOULEVARD                 \t\n",
      "BELMONT AVENUE                   \t BELMONT AVENUE                   \t\n",
      "nan \t  \t*\n",
      "BROOME STREET                    \t BROOME STREET                    \t\n",
      "ENGERT AVENUE                    \t ENGERT AVENUE                    \t\n",
      "SOUNDVIEW AVENUE                 \t SOUNDVIEW AVENUE                 \t\n",
      "FATHER CAPODANNO BOULEVARD       \t FATHER CAPODANNO BOULEVARD       \t\n",
      "ST. MARKS PLACE                  \t ST MARKS PLACE                  \t*\n",
      "EAST 91ST STREET                 \t EAST 91ST STREET                 \t\n",
      "RIVINGTON STREET                 \t RIVINGTON STREET                 \t\n",
      "35 AVE                           \t 35 AVE                           \t\n",
      "CARROLL STREET                   \t CARROLL STREET                   \t\n",
      "12 AVENUE                        \t 12 AVENUE                        \t\n",
      "UTICA AVENUE                     \t UTICA AVENUE                     \t\n",
      "BEACH CHANNEL DRIVE              \t BEACH CHANNEL DRIVE              \t\n",
      "95TH AVENUE                      \t 95TH AVENUE                      \t\n",
      "MYRTLE AVE                       \t MYRTLE AVE                       \t\n",
      "EAST 25TH STREET                 \t EAST 25TH STREET                 \t\n",
      "83RD STREET                      \t 83RD STREET                      \t\n",
      "5 AVENUE                         \t 5 AVENUE                         \t\n",
      "ST. MARKS AVENUE                 \t ST MARKS AVENUE                 \t*\n",
      "WEST 107 STREET                  \t WEST 107 STREET                  \t\n",
      "QUINTARD STREET                  \t QUINTARD STREET                  \t\n",
      "*    46  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Job Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "122851459 \t 122851459 \t\n",
      "321113451 \t 321113451 \t\n",
      "122415662 \t 122415662 \t\n",
      "122409018 \t 122409018 \t\n",
      "320922659 \t 320922659 \t\n",
      "122454156 \t 122454156 \t\n",
      "122366411 \t 122366411 \t\n",
      "121769309 \t 121769309 \t\n",
      "440239378 \t 440239378 \t\n",
      "321238718 \t 321238718 \t\n",
      "122415724 \t 122415724 \t\n",
      "440234088 \t 440234088 \t\n",
      "121600918 \t 121600918 \t\n",
      "420966397 \t 420966397 \t\n",
      "122470307 \t 122470307 \t\n",
      "421156420 \t 421156420 \t\n",
      "421023163 \t 421023163 \t\n",
      "421081670 \t 421081670 \t\n",
      "122532811 \t 122532811 \t\n",
      "321204898 \t 321204898 \t\n",
      "122090058|01|1|105         |EDGECOMB AVENUE                 |02048|00025|1060908|A3|R|PERMIT ISSUED - ENTIRE JOB/WORK         |01/15/2015 00:00:00|OTHER|110||| |X|ANTENNA        |JAMES          |FAHEY                         |PE|078939||08/06/2014 00:00:00|08/06/2014 00:00:00|08/06/2014 00:00:00|08/07/2014 00:00:00|01/15/2015 00:00:00|01/15/2015 00:00:00|5500.00|245.30|STANDARD|RES |RES |R7-2        |||||03|PARTNERSHIP                             |N|ROBERT         |RAPHAEL                       |582 ST. NICHOLAS ASSOCIATES \t 122090058|01|1|105         |EDGECOMB AVENUE                 |02048|00025|1060908|A3|R|PERMIT ISSUED - ENTIRE JOB/WORK         |01/15/2015 00:00:00|OTHER|110||| |X|ANTENNA        |JAMES          |FAHEY                         |PE|078939||08/06/2014 00:00:00|08/06/2014 00:00:00|08/06/2014 00:00:00|08/07/2014 00:00:00|01/15/2015 00:00:00|01/15/2015 00:00:00|5500.00|245.30|STANDARD|RES |RES |R7-2        |||||03|PARTNERSHIP                             |N|ROBERT         |RAPHAEL                       |582 ST. NICHOLAS ASSOCIATES \t\n",
      "321248903 \t 321248903 \t\n",
      "122207744 \t 122207744 \t\n",
      "122466535 \t 122466535 \t\n",
      "122463253 \t 122463253 \t\n",
      "122362111 \t 122362111 \t\n",
      "123017537 \t 123017537 \t\n",
      "321518201 \t 321518201 \t\n",
      "321164903 \t 321164903 \t\n",
      "420902795|01|4|103-14      |ROOSEVELT AVENUE                |01975|00009|4048557|A3|R|PERMIT ISSUED - ENTIRE JOB/WORK         |05/22/2014 00:00:00|OTHER|404||| |X|ANTENNA        |GLENN          |SCHERER                       |PE|075376||10/04/2013 00:00:00|10/04/2013 00:00:00|10/04/2013 00:00:00|10/28/2013 00:00:00|05/22/2014 00:00:00|05/22/2014 00:00:00|30000.00|492.50|STANDARD|C   |C   |R6B         |||||03|PARTNERSHIP                             |N|ROBERT         |ZELMAN                        |PLAZA CORONA HOLDINGS LLC       |17          |BARSTOW ROAD                    |GREAT NECK     |NY|11021    |5164668114|05/22/2014 00:00:00|REMOVE AND REPLACE TELECOMMUNICATION ANTENNAS ON THE ROOF.  ADD NEW              TELECOMMUNICATION EQUIPMENT IN EXISTING ROOM.  NO CHANGE IN USE \t 420902795|01|4|103-14      |ROOSEVELT AVENUE                |01975|00009|4048557|A3|R|PERMIT ISSUED - ENTIRE JOB/WORK         |05/22/2014 00:00:00|OTHER|404||| |X|ANTENNA        |GLENN          |SCHERER                       |PE|075376||10/04/2013 00:00:00|10/04/2013 00:00:00|10/04/2013 00:00:00|10/28/2013 00:00:00|05/22/2014 00:00:00|05/22/2014 00:00:00|30000.00|492.50|STANDARD|C   |C   |R6B         |||||03|PARTNERSHIP                             |N|ROBERT         |ZELMAN                        |PLAZA CORONA HOLDINGS LLC       |17          |BARSTOW ROAD                    |GREAT NECK     |NY|11021    |5164668114|05/22/2014 00:00:00|REMOVE AND REPLACE TELECOMMUNICATION ANTENNAS ON THE ROOF.  ADD NEW              TELECOMMUNICATION EQUIPMENT IN EXISTING ROOM.  NO CHANGE IN USE \t\n",
      "122333527 \t 122333527 \t\n",
      "321168106 \t 321168106 \t\n",
      "220286429 \t 220286429 \t\n",
      "520242345 \t 520242345 \t\n",
      "122453246 \t 122453246 \t\n",
      "321126189 \t 321126189 \t\n",
      "122203908 \t 122203908 \t\n",
      "421094522 \t 421094522 \t\n",
      "321210765 \t 321210765 \t\n",
      "340288539 \t 340288539 \t\n",
      "321126349 \t 321126349 \t\n",
      "420812197 \t 420812197 \t\n",
      "421481523 \t 421481523 \t\n",
      "420901171 \t 420901171 \t\n",
      "122678584 \t 122678584 \t\n",
      "421208614 \t 421208614 \t\n",
      "122726611 \t 122726611 \t\n",
      "321100615 \t 321100615 \t\n",
      "123048914 \t 123048914 \t\n",
      "520241444 \t 520241444 \t\n",
      "*    50  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Doc Number\n",
      "Original,\t Cleaned\n",
      "\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      " LLC|55          |WATERMILL LANE                  |GREAT NECK     |NY|11021    |5167640226|01/15/2015 00:00:00|MODIFICATION TO EXISTING TELECOMMUNICATIONS SITE. REPLACEMENT OF (5) ANTENNAS    WITH RELATED RRH UNITS ON ROOF. ALL IN CONFORMANCE WITH TPPN 5/98. NO CHANGE IN  USE \t  LLC|55          |WATERMILL LANE                  |GREAT NECK     |NY|11021    |5167640226|01/15/2015 00:00:00|MODIFICATION TO EXISTING TELECOMMUNICATIONS SITE. REPLACEMENT OF (5) ANTENNAS    WITH RELATED RRH UNITS ON ROOF. ALL IN CONFORMANCE WITH TPPN 5/98. NO CHANGE IN  USE \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      " EGRESS OR       OCCUPANCY.  ALL WORK IS IN COMPLIANCE WITH TPPN 5/98.                           |05/23/2014 00:00:00 \t  EGRESS OR       OCCUPANCY.  ALL WORK IS IN COMPLIANCE WITH TPPN 5/98.                           |05/23/2014 00:00:00 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "01 \t 01 \t\n",
      "*    50  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Pre- Filing Date\n",
      "Original,\t Cleaned\n",
      "\n",
      "08/04/2016 12:00:00 AM \t 2016-08-04 00:00:00 \t*\n",
      "04/24/2015 12:00:00 AM \t 2015-04-24 00:00:00 \t*\n",
      "05/27/2015 12:00:00 AM \t 2015-05-27 00:00:00 \t*\n",
      "05/22/2015 12:00:00 AM \t 2015-05-22 00:00:00 \t*\n",
      "03/10/2014 12:00:00 AM \t 2014-03-10 00:00:00 \t*\n",
      "07/02/2015 12:00:00 AM \t 2015-07-02 00:00:00 \t*\n",
      "04/16/2015 12:00:00 AM \t 2015-04-16 00:00:00 \t*\n",
      "09/05/2013 12:00:00 AM \t 2013-09-05 00:00:00 \t*\n",
      "07/29/2015 12:00:00 AM \t 2015-07-29 00:00:00 \t*\n",
      "10/01/2015 12:00:00 AM \t 2015-10-01 00:00:00 \t*\n",
      "05/27/2015 12:00:00 AM \t 2015-05-27 00:00:00 \t*\n",
      "07/10/2015 12:00:00 AM \t 2015-07-10 00:00:00 \t*\n",
      "04/25/2013 12:00:00 AM \t 2013-04-25 00:00:00 \t*\n",
      "04/07/2014 12:00:00 AM \t 2014-04-07 00:00:00 \t*\n",
      "07/17/2015 12:00:00 AM \t 2015-07-17 00:00:00 \t*\n",
      "06/18/2015 12:00:00 AM \t 2015-06-18 00:00:00 \t*\n",
      "08/26/2014 12:00:00 AM \t 2014-08-26 00:00:00 \t*\n",
      "02/19/2015 12:00:00 AM \t 2015-02-19 00:00:00 \t*\n",
      "09/22/2015 12:00:00 AM \t 2015-09-22 00:00:00 \t*\n",
      "08/17/2015 12:00:00 AM \t 2015-08-17 00:00:00 \t*\n",
      "nan \t 2016-02-29 00:00:00 \t*\n",
      "09/29/2015 12:00:00 AM \t 2015-09-29 00:00:00 \t*\n",
      "12/16/2014 12:00:00 AM \t 2014-12-16 00:00:00 \t*\n",
      "07/15/2015 12:00:00 AM \t 2015-07-15 00:00:00 \t*\n",
      "07/13/2015 12:00:00 AM \t 2015-07-13 00:00:00 \t*\n",
      "04/15/2015 12:00:00 AM \t 2015-04-15 00:00:00 \t*\n",
      "02/08/2017 12:00:00 AM \t 2017-02-08 00:00:00 \t*\n",
      "01/31/2017 12:00:00 AM \t 2017-01-31 00:00:00 \t*\n",
      "07/17/2015 12:00:00 AM \t 2015-07-17 00:00:00 \t*\n",
      "nan \t 2016-04-27 00:00:00 \t*\n",
      "03/11/2015 12:00:00 AM \t 2015-03-11 00:00:00 \t*\n",
      "07/20/2015 12:00:00 AM \t 2015-07-20 00:00:00 \t*\n",
      "04/26/2013 12:00:00 AM \t 2013-04-26 00:00:00 \t*\n",
      "05/01/2015 12:00:00 AM \t 2015-05-01 00:00:00 \t*\n",
      "07/01/2015 12:00:00 AM \t 2015-07-01 00:00:00 \t*\n",
      "05/05/2015 12:00:00 AM \t 2015-05-05 00:00:00 \t*\n",
      "11/21/2014 12:00:00 AM \t 2014-11-21 00:00:00 \t*\n",
      "04/21/2015 12:00:00 AM \t 2015-04-21 00:00:00 \t*\n",
      "08/21/2015 12:00:00 AM \t 2015-08-21 00:00:00 \t*\n",
      "08/04/2015 12:00:00 AM \t 2015-08-04 00:00:00 \t*\n",
      "05/05/2015 12:00:00 AM \t 2015-05-05 00:00:00 \t*\n",
      "02/11/2013 12:00:00 AM \t 2013-02-11 00:00:00 \t*\n",
      "05/10/2017 12:00:00 AM \t 2017-05-10 00:00:00 \t*\n",
      "09/27/2013 12:00:00 AM \t 2013-09-27 00:00:00 \t*\n",
      "02/05/2016 12:00:00 AM \t 2016-02-05 00:00:00 \t*\n",
      "08/28/2015 12:00:00 AM \t 2015-08-28 00:00:00 \t*\n",
      "03/18/2016 12:00:00 AM \t 2016-03-18 00:00:00 \t*\n",
      "03/26/2015 12:00:00 AM \t 2015-03-26 00:00:00 \t*\n",
      "03/21/2017 12:00:00 AM \t 2017-03-21 00:00:00 \t*\n",
      "04/15/2015 12:00:00 AM \t 2015-04-15 00:00:00 \t*\n",
      "*    0  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "column:  Applicant's Last Name\n",
      "Original,\t Cleaned\n",
      "\n",
      "SCHWARTZ                       \t SCHWARTZ                       \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "FAHEY                          \t FAHEY                          \t\n",
      "TARDY                          \t TARDY                          \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "KRAFFT                         \t KRAFFT                         \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "SCHWARTZ                       \t SCHWARTZ                       \t\n",
      "FAHEY                          \t FAHEY                          \t\n",
      "TARDY                          \t TARDY                          \t\n",
      "WITCZAK                        \t WITCZAK                        \t\n",
      "GUALTIERI                      \t GUALTIERI                      \t\n",
      "NOWAK                          \t NOWAK                          \t\n",
      "FAHEY                          \t FAHEY                          \t\n",
      "PAZDEN                         \t PAZDEN                         \t\n",
      "PAPAY                          \t PAPAY                          \t\n",
      "BOHLINGER                      \t BOHLINGER                      \t\n",
      "BARILE                         \t BARILE                         \t\n",
      "nan \t  \t*\n",
      "PAPAY                          \t PAPAY                          \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "BURTNER                        \t BURTNER                        \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "NOWAK                          \t NOWAK                          \t\n",
      "BARILE                         \t BARILE                         \t\n",
      "WHELAN                         \t WHELAN                         \t\n",
      "TOMS                           \t TOMS                           \t\n",
      "nan \t  \t*\n",
      "ADELY                          \t ADELY                          \t\n",
      "PAPAY                          \t PAPAY                          \t\n",
      "BRAY                           \t BRAY                           \t\n",
      "BRAY                           \t BRAY                           \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "BARILE                         \t BARILE                         \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "FAHEY                          \t FAHEY                          \t\n",
      "TARDY                          \t TARDY                          \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "BARILE                         \t BARILE                         \t\n",
      "ADELY                          \t ADELY                          \t\n",
      "BRAY                           \t BRAY                           \t\n",
      "TOMS                           \t TOMS                           \t\n",
      "BURNTER                        \t BURNTER                        \t\n",
      "MACDONALD                      \t MACDONALD                      \t\n",
      "GUALTIERI                      \t GUALTIERI                      \t\n",
      "BOHLINGER                      \t BOHLINGER                      \t\n",
      "BARILE                         \t BARILE                         \t\n",
      "SCHWARTZ                       \t SCHWARTZ                       \t\n",
      "*    48  same records   *\n",
      "\n",
      "======================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision_recall(cleaned_cols, datafile, df, 50, col_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 100\n",
    "fp = 0\n",
    "\n",
    "fn = 13\n",
    "tn = 1350 - tp - fp - fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/3827113854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "precision(tp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/785133604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "recall(tp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Restaurant Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:  pitm-atqc.tsv.gz\n",
      "fixing Column Names.......\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str.replace() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/4004300857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_rename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataCleanOnDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/77753700.py\u001b[0m in \u001b[0;36mdataCleanOnDataset\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fixing Column Names.......\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcol_rename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfixColumnNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print(\"Column renaming dictionary:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(col_rename_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/3305879432.py\u001b[0m in \u001b[0;36mfixColumnNames\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Number\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: str.replace() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "cleaned_cols, datafile, df, col_rename_dict = dataCleanOnDataset(file_list[2])\n",
    "cleaned_cols = list(set(cleaned_cols))\n",
    "\n",
    "print(cleaned_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(cleaned_cols, datafile, df, 50, col_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 442\n",
    "fp = 128\n",
    "\n",
    "fn = 39\n",
    "tn = 1900 - tp - fp - fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(tp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/785133604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "recall(tp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOB NOW: Safety – Facades Compliance Filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:  xubg-57si.tsv.gz\n",
      "fixing Column Names.......\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str.replace() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/3517378158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcleaned_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_rename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataCleanOnDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcleaned_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/77753700.py\u001b[0m in \u001b[0;36mdataCleanOnDataset\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fixing Column Names.......\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcol_rename_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfixColumnNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print(\"Column renaming dictionary:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(col_rename_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9612/3305879432.py\u001b[0m in \u001b[0;36mfixColumnNames\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Number\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: str.replace() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "cleaned_cols, datafile, df, col_rename_dict = dataCleanOnDataset(file_list[3])\n",
    "cleaned_cols = list(set(cleaned_cols))\n",
    "\n",
    "print(cleaned_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall(cleaned_cols, datafile, df, 50, col_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 273\n",
    "fp = 50\n",
    "\n",
    "fn = 86\n",
    "tn = 1150 - tp - fp - fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(tp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall(tp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
