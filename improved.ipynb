{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openclean\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import humanfriendly\n",
    "import os\n",
    "\n",
    "from openclean.data.source.socrata import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openclean.pipeline import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"*.tsv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(file):\n",
    "    \n",
    "    datafile = './'+file\n",
    "    \n",
    "    df  = pd.read_csv(datafile, dtype='object', sep='\\t')\n",
    "    ds = stream(datafile)\n",
    "    \n",
    "    return datafile, df, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColumns(ds, column_name_list):\n",
    "    data_cols = []\n",
    "\n",
    "    for col in ds.columns:\n",
    "        for name in column_name_list:\n",
    "            if name in col:\n",
    "                data_cols.append(col)\n",
    "                \n",
    "    return  data_cols        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ID_Number_Column(df, ds):\n",
    "    data_cols = findColumns(ds, ['ID','id','#','Number', 'number',' No',' NO'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col].fillna('', inplace=True)\n",
    "        df[col] = df[col].astype('str')\n",
    "        df[col] = df[col].str.upper()\n",
    "\n",
    "        df.loc[df[col].str.strip('')=='ONE', col] = '1'\n",
    "        df.loc[df[col].str.strip('')=='TWO', col] = '2'\n",
    "        df.loc[df[col].str.strip('')=='THREE', col] = '3'\n",
    "        df.loc[df[col].str.strip('')=='FOUR', col] = '4'\n",
    "        df.loc[df[col].str.strip('')=='FIVE', col] = '5'\n",
    "        df.loc[df[col].str.strip('')=='SIX', col] = '6'\n",
    "        df.loc[df[col].str.strip('')=='SEVEN', col] = '7'\n",
    "        df.loc[df[col].str.strip('')=='EIGHT', col] = '8'\n",
    "        df.loc[df[col].str.strip('')=='NINE', col] = '9'\n",
    "\n",
    "        df.loc[df[col].str.strip('')=='NAN', col] = ''\n",
    "        df.loc[df[col].str.strip('')=='nan', col] = ''\n",
    "        \n",
    "        df.loc[df[col].str.strip('')=='NO NUMBER', col] = ''\n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Binary_Column(df, ds):\n",
    "    data_cols = findColumns(ds, ['Landmarked','Owned', 'Filled'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col].fillna('N', inplace=True)\n",
    "        df.loc[df[col]=='X', col] = 'Y'\n",
    "        \n",
    "        df.loc[df[col]=='Y', col] = True\n",
    "        df.loc[df[col]!=True, col] = False\n",
    "        \n",
    "        df[col] = df[col].astype('bool')\n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Monetary_Column(df, ds):\n",
    "    data_cols = findColumns(ds, ['Cost','cost', 'fee', 'Fee'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col] = df[col].str.replace(\"$\", '', regex=False)\n",
    "        df[col] = df[col].astype('float')\n",
    "        df.loc[df[col] < 0, col] *= -1\n",
    "        \n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_Numerical_Column(df, ds):\n",
    "    data_cols = findColumns(ds, ['Units','units', 'Height', 'height', 'Length', 'length', 'Footage', 'footage', 'Sqft', 'sqft'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col] = df[col].str.replace('-', '', regex=False)\n",
    "        df[col] = df[col].str.replace('NONE', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('none', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('NAN', '0', regex=False)\n",
    "        df[col] = df[col].str.replace('nan', '0', regex=False)\n",
    "        \n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.profiling.anomalies.sklearn import DBSCANOutliers\n",
    "\n",
    "def findDateOutliers(df, ds, column_name, eps_setting = 0.05):\n",
    "    datetime_data = df[column_name]\n",
    "\n",
    "    light_outliers = DBSCANOutliers().find(datetime_data)\n",
    "    \n",
    "    return light_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datetime_Column(df, ds):\n",
    "    data_cols = findColumns(ds, ['date', 'Date', 'DATE'])\n",
    "    \n",
    "    for col in data_cols:\n",
    "    \n",
    "        \n",
    "        light_outliers = findDateOutliers(df, ds, col)\n",
    "        \n",
    "        for item in light_outliers:\n",
    "            \n",
    "            df[col] = df[col].replace(item, None)\n",
    "        \n",
    "    return data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.data.refdata import RefStore\n",
    "\n",
    "refdata = RefStore()\n",
    "city_df = refdata\\\n",
    "    .load('encyclopaedia_britannica:us_cities', auto_download=True)\\\n",
    "    .df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster string using kNN clusterer (with the default n-gram setting)\n",
    "# using the Levenshtein distance as the similarity measure.\n",
    "\n",
    "from openclean.cluster.knn import knn_clusters\n",
    "from openclean.function.similarity.base import SimilarityConstraint\n",
    "from openclean.function.similarity.text import LevenshteinDistance\n",
    "from openclean.function.value.threshold import GreaterThan\n",
    "\n",
    "def getClusters(df, ds, col, minsize = 2, preds = 0.5):\n",
    "    dba = ds.select(col).distinct()\n",
    "    clusters = knn_clusters(\n",
    "        values=dba,\n",
    "        sim=SimilarityConstraint(func=LevenshteinDistance(), pred=GreaterThan(preds)),\n",
    "        minsize=minsize\n",
    "    )\n",
    "    return clusters\n",
    "\n",
    "def print_cluster(cnumber, cluster):\n",
    "    item_count = 0\n",
    "\n",
    "def updateUsingClusters(df, ds, col, clusters, isPrint = False):\n",
    "    \n",
    "    orignal_list = []\n",
    "    suggestion_list = []\n",
    "    clusters.sort(key=lambda c: len(c), reverse=True)\n",
    "       \n",
    "    for i, cluster in enumerate(clusters):        \n",
    "        suggestion = cluster.suggestion()\n",
    "        orignal_list = []\n",
    "        suggestion_list = []\n",
    "        if isPrint and i <5:\n",
    "            print_cluster(i, cluster)\n",
    "        \n",
    "        for val, count in cluster.items(): \n",
    "            orignal_list.append(val)\n",
    "            suggestion_list.append(suggestion)\n",
    "    \n",
    "    df[col] = df[col].replace(orignal_list, suggestion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean.function.eval.base import Col, Eval\n",
    "from openclean.function.eval.logic import And\n",
    "from openclean.function.value.phonetic import Soundex, soundex\n",
    "\n",
    "\n",
    "def fix_city_and_name_Column(df, ds, file):\n",
    "    data_cols = findColumns(ds, ['NAME', 'name', 'Name','city', 'City', 'CITY', 'BOROUGH', 'Borough', 'borough'])\n",
    "    name_cols = findColumns(ds, ['NAME', 'name', 'Name'])\n",
    "    \n",
    "    # mapping list to replace outliers\n",
    "    outlier1 = ['', 'MR. ROSS ADAM C', 'MICHAEL', 'N. J.', 'WILLIAM 11', 'JOSEP;H``', 'DAID/11/2007', 'CHUNG   LUN', '718 9215010', 'ANTHONY', 'HSIA0-NAN', 'JOSEPH', '``````````', 'ROBERT  `', 'RAJENDRA9956700', '2', 'G.B.M.', 'EUGENE......JR', '6312100', 'CLAUDE,JR.', 'THOMAS``', 'ALAN  L', 'Nab53', 'MR. Y. B', 'J.J', 'PH8ILIP', 'I. M', 'RICHARD', 'ALBERTA S 111 D', 'P ;', 'GENECG.C. ENG &', 'J.J.', '2126202794', 'SHAW  HWA', 'HARRY         H', 'MR DOU8GLAS', '`1D', 'PAUL', 'K. T.', 'JOHN', '...NORMAN', 'EVAN   D', '7184361278BERNA', 'S.D. DON', 'KY00 SUK', 'JJ', 'YURI.`', 'MAD/Y/ARNI', 'ES ON SCH B', 'EUGENE.......JR', 'NEAL', 'F._ERIC', 'RYAN,  JR', 'AASDFASDFASDF', 'LA0-TECH', 'RODNEY   __', 'DAVID', 'G. L.', 'JAMES', 'LESLI8E', '7186054055', 'GEORGE', 'G.B.M', 'DAVID    JON', 'CHUNG---YAO', 'PETER', 'YUBUN(JACK)', 'GLEN A. L.', '1P', 'JUDE.....N.O', 'LEONARD--', 'WILLIAM', 'ANTHONY,111', 'WU(WOODY)', 'GAD/HON-AN', 'GLEN  A.L.', 'J.B. Jr.', 'LORENZO..A', 'J J', '..RAMSEY', 'HUI LI I', 'ANTONIO9', 'ROBERT', '0.BERT', 'DUMMY 2', '...JOSEPH', 'RUSSELL 111', 'THOMAS', 'H./E./CAMELLE', 'LALAL', 'M.E. P.E', 'R0OBIN VINCENT', '--young', 'AKM', 'LE1', 'IK.T.', 'LEO, JR.', 'J. Butch A. Jr.', 'WU (WOODY0', 'PAUL   N', 'CHRISTOPHER']\n",
    "    mapping1 = [None, 'ROSS ADAM C', 'MICHAEL', 'N. J.', 'WILLIAM', 'JOSEPH', None, 'CHUNG LUN', None, 'ANTHONY', 'HSIA0 NAN', 'JOSEPH', None, 'ROBERT', 'RAJENDRA', None, 'G.B.M.', 'EUGENEJR', None, 'CLAUDE JR.', 'THOMAS', 'ALAN  L', 'Nab', 'MR. Y. B', 'J.J', 'PHILIP', 'I. M', 'RICHARD', 'ALBERTA', None, 'GENECG.C. ENG', 'J.J.', None, 'SHAW HWA', 'HARRYH', 'MR DOUGLAS', None, 'PAUL', 'K. T.', 'JOHN', 'NORMAN', 'EVAND', 'BERNA', 'S.D. DON', 'KY00 SUK', 'JJ', 'YURI.`', 'MADYARNI', 'ES ON SCH B', 'EUGENEJR', 'NEAL', 'FERIC', 'RYAN,  JR', 'AASDFASDFASDF', 'LA0 TECH', 'RODNEY', 'DAVID', 'G. L.', 'JAMES', 'LESLIE', None, 'GEORGE', 'G.B.M', 'DAVID JON', 'CHUNG YAO', 'PETER', 'YUBUN(JACK)', 'GLEN A. L.', None, 'JUDE N.O', 'LEONARD--', 'WILLIAM', 'ANTHONY,111', 'WU(WOODY)', 'GAD HON-AN', 'GLEN A.L.', 'J.B. Jr.', 'LORENZOA', 'J J', 'RAMSEY', 'HUI LI I', 'ANTONIO9', 'ROBERT', '0.BERT', 'DUMMY', 'JOSEPH', 'RUSSELL', 'THOMAS', 'H.E.CAMELLE', 'LALAL', 'M.E. P.E', 'R0OBIN VINCENT', 'young', 'AKM', 'LE1', 'IK.T.', 'LEO, JR.', 'J. Butch A. Jr.', 'WU (WOODY0', 'PAUL   N', 'CHRISTOPHER']\n",
    "\n",
    "    outlier2 = ['SHARMA #0', \"0'CONNOR\", 'RUSHTON    UEL', 'UDDIN   Z', 'HINKLEY 1', 'O&#039;CONNOR, P.E.', '.OOK', 'SAMUELS111', 'O&#039;CONNOR', 'CALIENDO', 'SMITH   JR.', 'LO  BUE', '7AN', '+-+ETTIERI', 'SMITH, 111', 'KAMEN   1', '.EE', 'MASS, 1', '.EI', 'Zagaroli 3rd', 'RINI   II', 'KAMEN   R', 'RYAN 11', 'SPI8EZIA L S', 'MUFTIC..A.I.A', 'COSTELLO9 RA A I A', 'CALVANICO', 'LLC.', 'POEPPEL, P.E.', 'HAMA07', 'HINLEY,1', '1212', \"O  ' CONNELL\", 'HURT,JR.,', 'WESOLOWSKI', 'CHEN', '`ING, R.A', 'MARTARELLA 111', 'Gandhi, Ph.D., P.E.', '90I', 'ENNIS 2', 'COSTELLO R A A I A', '3UI', 'N/A', 'HURT,  JR', 'LEHR,1', 'KOHLER, 111', 'GERAZOUNIS', 'Alexander,1', 'LUBOW, R.A. LEED AP', 'RINI,111', '08CZAK', '````````````````````', 'CHAO  R.A.', 'Geier 11', '08NGEL', '08SOLOWSKI', 'I11', 'HINKLEY, 1', 'RUDIKOFF, P.E.', \"O'CONNOR\", 'SHAH   EZ', 'MIELE, JR., P.E.', 'RITTENHOUSE 111', 'AMADI   ISIOFIA', 'HINKLEY,1', 'RENFORE````````', \"O'HARA,JR.\", '73020012', 'PHAGOO   I', 'BRAY.....,', 'LLL', 'BHATHIA,1', 'GANDHI, PH. D., P.E', 'KO K', 'VASSALOTTI 11', 'HURT, JR .', '0018LKLE', 'RINI -111', 'PARIHAR', 'EE', 'L00802', 'ELISE.111', 'KING , R.A', 'CHRYSLER  P E', 'LEHR 1', 'Walters   Jr.', 'LEE', 'RINI  III', 'D&#039;ANGELO', '0UDOLPH III', 'VIEHE-NAESS 111', ',MO', '08E', '47DIKOFF', 'Yu,', '420865380', 'COPELAND', 'ZWIEFEL 3RD', 'PETERSEN', 'King, R.A.,', 'RINI, III', '7APA', 'CHEN   S', 'Hurt  Jr.', 'KATZ', 'NIZAMBAD.(P.E.)', '901BEN', '4153LOO', 'SYED-NAQVI', 'RYAN , JR.', 'K O K O R I S', 'ELISEO111', 'O&#039;CONNELL', 'ZEID61', '---Lewis', '00CHELI', 'MOHAMMAD       +++++', 'METZLER  P E', 'BAILEY', 'GANDHI, PH. D., P.E.', 'TIEMANN.111', 'SMITH.111', 'DI GER0NIMO', 'GANDHI, PH,D., P.E', 'III', 'J C', 'MAGAMI-QAIM-MAGAMI', '+M', 'LO G1UDICE', 'HOQUE', 'RUDIKOFF', 'Y10007OR', 'SMITH,111', 'KING R A FAIA', 'RYAN III, AIA', '08AN', 'STARK 1', 'MASS', 'VICTORI0, R.A', 'RIZVI   A', '21029677', \"3'CONNOR\", 'Wong /  Lai', 'KAPLAN 3', 'GRAICHEN.JR./DAWN/DI', 'GROSSMAN ,PE,F.A.C.I']\n",
    "    mapping2 = ['SHARMA ', \"CONNOR\", 'RUSHTON UEL', 'UDDIN Z', 'HINKLEY ', 'CONNOR P.E.', None, 'SAMUELS', 'CONNOR', 'CALIENDO', 'SMITH JR.', 'LO BUE', None, 'ETTIERI', 'SMITH', 'KAMEN', '.EE', 'MASS', '.EI', 'Zagaroli', 'RINI', 'KAMEN R', 'RYAN', 'SPIEZIA L S', 'MUFTIC.A.I.A', 'COSTELLO9 RA A I A', 'CALVANICO', 'LLC.', 'POEPPEL P.E.', 'HAMA', 'HINLEY', None, \"CONNELL\", 'HURT JR.', 'WESOLOWSKI', 'CHEN', 'ING R.A', 'MARTARELLA', 'Gandhi', None, 'ENNIS ', 'COSTELLO R A A I A', None, None, 'HUR  JR', 'LEHR', 'KOHLER 111', 'GERAZOUNIS', 'Alexander', 'LUBOW R.A. LEED AP', 'RINI',None, None, 'CHAO R.A.', 'Geier', None, 'SOLOWSKI', None, 'HINKLEY', 'RUDIKOFF, P.E.', \"CONNOR\", 'SHAH EZ', 'MIELE JR. P.E.', 'RITTENHOUSE', 'AMADI   ISIOFIA', 'HINKLEY', 'RENFORE', \"O'HARA,JR.\", None, 'PHAGOO I', 'BRAY,', 'LLL', 'BHATHIA', 'GANDHI', 'KO K', 'VASSALOTTI', 'HURT JR.',None, 'RINI', 'PARIHAR', 'EE', None, 'ELISE', 'KING R.A', 'CHRYSLER  P E', 'LEHR', 'Walters Jr.', 'LEE', 'RINI  III', 'ANGELO', '0UDOLPH III', 'VIEHE-NAESS', 'MO', '08E', None, 'Yu,', None, 'COPELAND', 'ZWIEFEL 3RD', 'PETERSEN', 'King, R.A.,', 'RINI, III', '7APA', 'CHEN   S', 'Hurt  Jr.', 'KATZ', 'NIZAMBAD.(P.E.)', None, None, None, 'RYAN JR.', 'KOKORIS', 'ELISE', 'CONNELL', None, 'Lewis', 'CHELI', 'MOHAMMAD', 'METZLER  P E', 'BAILEY', 'GANDHI', 'TIEMANN', 'SMITH', 'DI GER0NIMO', 'GANDHI', 'III', 'J C', 'MAGAMI QAIM MAGAMI', None, 'LO G1UDICE', 'HOQUE', 'RUDIKOFF', None, 'SMITH', 'KING R A FAIA', 'RYAN III AIA', None, 'STARK', 'MASS', 'VICTORI0 R.A', 'RIZVIA', None, \"CONNOR\", 'Wong Lai', 'KAPLAN', 'GRAICHEN.JR. DAWN DI', 'GROSSMAN']\n",
    "\n",
    "    outlier3 = ['', '....DEMO', '050069', 'DEM. CONTR.,', 'XXXXX', 'G/C 10114H9', 'CGWC10114H99', '00', 'X S000155', '082-36-1245', 'G.G', 'LESSEE', '......GC', \"'\", '..OWNER', 'GC 2293', '--', 'XXXXXX', 'LS 31,721', '...GC', 'gen.cont.', 'G.C TK#4592', 'PE', 'RLA - 818', '.....OWNER', 'RLA 16077', 'G C', 'X 4129892', 'G. C.', 'R.L.A', 'GC 1028350', 'WC10114H99', 'LEESEE', 'GEN.CONT.', 'SIGN..HANGER', 'DEMO 20451', 'D8615', '.X', 'P.L.L.C', '..DEMO', 'G .C', 'L A', 'G.C NY11101', '32820', '....OWNER', 'GC(DEMO)', 'C0NTRACTOR', 'EXPEDITORC99792', 'X 1341946', 'TRACK# 1390', 'EXPED.R4466', 'PLLC 9599691', 'G.C 1110101', '029649', '(CHECK)', 'DEM. CONTR,', 'EXPEDIT(H66172)', '.........GC', 'CITY OF N Y', 'GC 1170386', 'G. C', 'CO0OWNER', '(CHECKED)', 'C.C', '23392 1159774', 'DEMO {', 'RA', 'T. 31132', '....GC', 'RLA-787', 'TRACK #1390', 'D C', 'G.CONTR.', 'DEMO  CONT', '1GC', 'CC', 'demo G.C.', 'TRACK. #1390', 'M.F.S.P.C.', '...DEMO', 'DEMO G C', '13328', 'GEN  CONT', 'GC 1221073', \"GC;'\", 'DEMO 1341946', '11234', 'G.C.,', '.....GC', 'LIC.133668259 1', '?', '0WNER', 'C10892', 'GEN..CONT']\n",
    "    mapping3 = [None, 'DEMO', None, 'DEM. CONTR', None, 'G/C', 'CGWC', None, 'X S', None, 'G.G', 'LESSEE', 'GC', None, 'OWNER', 'GC', None, None, 'LS ', 'GC', 'gen.cont.', 'G.C TK', 'PE', 'RLA ', 'OWNER', 'RLA ', 'G C', 'X', 'G. C.', 'R.L.A', 'GC', 'WC', 'LEESEE', 'GEN.CONT.', 'SIGN.HANGER', 'DEMO', None,None, 'P.L.L.C', 'DEMO', 'G.C', 'L A', 'G.C ', None, 'OWNER', 'GC(DEMO)', 'C0NTRACTOR', 'EXPEDITORC', None, 'TRACK', 'EXPED.R', 'PLLC ', 'G.C', None, None, 'DEM. CONTR,', 'EXPEDIT', 'GC', None, 'GC', 'G.C', 'CO0OWNER', None, 'C.C', None, 'DEMO', 'RA', None, 'GC', 'RLA', None, 'D C', 'G.CONTR.', 'DEMO  CONT', 'GC', 'CC', 'demo G.C.', None, 'M.F.S.P.C.', 'DEMO', 'DEMO G C', None, 'GEN  CONT', 'GC ', \"GC \", 'DEMO ', None, 'G.C.', 'GC', 'LIC', None, '0WNER',None, 'GEN.CONT']\n",
    "\n",
    "    outlier4 = ['', '0000GC', '083278', 'DD5615', '0000PB', '00ASB4', 'B81923', '99998', '000N/A', '65569+', '01827O', 'R9526', 'LP0256', 'N/A', '1964', 'ISLAND', '1609', '000PW1', '00DEMO', '0688.6', '00000', '.20929', 'LP0258', '000TOR', '0D8615', '0SWITA', '818', 'O02200', 'DEMO', '196', '1075', '0000NT', '215', '0', '00000`', \"D'ALTO\", '0455', '22377', 'DD8615', '050579', '226', 'SWITA', 'DD6815', 'X02689']\n",
    "    mapping4 = [None, '0000GC', '083278', 'DD5615', '0000PB', '00ASB4', 'B81923', '099998', '000000', '065569', '01827O', '0R9526', 'LP0256',None, '001964',None, '001609', '000PW1', '00DEMO', '006886', '000000', '020929', 'LP0258', '000TOR', '0D8615', '0SWITA', '000818', 'O02200', None, '000196', '001075', '0000NT', '000215', '000000', '000000', None, '000455', '022377', 'DD8615', '050579', '000226', None, 'DD6815', 'X02689']\n",
    "\n",
    "    outliers = outlier1+ outlier2+ outlier3+ outlier4\n",
    "    mappings = mapping1+ mapping2+ mapping3+ mapping4\n",
    "       \n",
    "    for col in data_cols:\n",
    "        \n",
    "        df[col] = df[col].replace(outliers, mappings)\n",
    "        light_outliers = findDateOutliers(df, ds, col)\n",
    "        \n",
    "        for item in light_outliers:\n",
    "            \n",
    "            df[col] = df[col].replace(item, None)\n",
    "        \n",
    "        if file != 'hg8x-zxpr.tsv.gz' and col in name_cols:\n",
    "            col_clusters = getClusters(df, ds, col)\n",
    "            updateUsingClusters(df, ds, col, col_clusters, True)\n",
    "            \n",
    "        df[col] = df[col].replace(['N/A', '', 'NA','NONE'], [None,None,None,None])\n",
    "        \n",
    "    return data_cols    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDf(df, datafile):\n",
    "    outputpath = datafile[2:11]+'_cleaned_data_improved.csv'\n",
    "    df.to_csv(outputpath,sep=',',index=False,header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleanOnDataset(file):\n",
    "    \n",
    "    print('working on file: ', file)\n",
    "    datafile, df, ds = readData(file)\n",
    "    \n",
    "    cleaned_cols = []\n",
    "    \n",
    "    print('fixing ID_Number_Column......')\n",
    "    cleaned_cols += fix_ID_Number_Column(df, ds)\n",
    "    \n",
    "    print('fixing Binary_Column......')\n",
    "    cleaned_cols += fix_Binary_Column(df, ds)\n",
    "    \n",
    "    print('fixing Monetary_Column......')\n",
    "    cleaned_cols += fix_Monetary_Column(df, ds)\n",
    "    \n",
    "    print('fixing Numerical_Column......')\n",
    "    cleaned_cols += fix_Numerical_Column(df, ds)\n",
    "    \n",
    "    print('fixing datetime_Column......')\n",
    "    cleaned_cols += fix_datetime_Column(df, ds)\n",
    "    \n",
    "    print('fixing city_and_name_Column......')\n",
    "    cleaned_cols += fix_city_and_name_Column(df, ds, file)\n",
    "    \n",
    "    saveDf(df, datafile)\n",
    "    \n",
    "    return cleaned_cols, datafile, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on file:  rbx6-tga4.tsv.gz\n",
      "fixing ID_Number_Column......\n",
      "fixing Binary_Column......\n",
      "fixing Monetary_Column......\n",
      "fixing Numerical_Column......\n",
      "fixing datetime_Column......\n",
      "fixing city_and_name_Column......\n"
     ]
    }
   ],
   "source": [
    "cleaned_cols, datafile, df = dataCleanOnDataset(file_list[3])\n",
    "print(cleaned_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp):\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(cleaned_columns, datafile, df):\n",
    "    df2  = pd.read_csv(datafile, dtype='object', sep='\\t')\n",
    "    df2 = df2.drop_duplicates()\n",
    "\n",
    "    sample_size = 50\n",
    "\n",
    "    df_sample_data =  df2.sample(sample_size).copy()\n",
    "    \n",
    "    print('sample size: ',sample_size)\n",
    "    \n",
    "    print('total size: ',sample_size * len(cleaned_columns))\n",
    "    print('======================\\n\\n')\n",
    "\n",
    "    same = 0\n",
    "\n",
    "    for col in cleaned_columns:\n",
    "        print(\"column: \", col)\n",
    "        print(\"Original,\\t Cleaned\\n\")\n",
    "        for i in range(sample_size):\n",
    "            if df[col].iloc[i]== df2[col].iloc[i]:\n",
    "                print(df[col].iloc[i], '\\t', df2[col].iloc[i], '\\t')\n",
    "                same += 1\n",
    "            else:\n",
    "                print(df[col].iloc[i], '\\t', df2[col].iloc[i], '\\t*')\n",
    "\n",
    "        print('*   ', same, ' same records   *\\n')\n",
    "        same = 0\n",
    "\n",
    "        print('======================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
